{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import midi\n",
    "import matplotlib.patches\n",
    "import matplotlib\n",
    "import djitw\n",
    "import scipy.spatial\n",
    "import librosa\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import tabulate\n",
    "import ujson as json\n",
    "import collections\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "matplotlib.rc('font',**{'size':16, 'family':'Open Sans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing colors\n",
    "\n",
    "BLUE = '#1a6396'\n",
    "GREEN = '#59dd97'\n",
    "ORANGE = '#E8B71A'\n",
    "GREY = '#DFDFDF'\n",
    "RED = '#DB3340'\n",
    "TAN = '#F7EAC8'\n",
    "FIGSIZE = (9, 6)\n",
    "FIGSIZE_FLAT = (9, 2)\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.gca().add_patch(plt.Rectangle((-1, -1), 8, 1.5, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((0, 0), 1, 1, fc=BLUE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((1, 0), 1, 1, fc=GREEN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((2, 0), 1, 1, fc=GREY, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((3, 0), 1, 1, fc=RED, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((4, 0), 1, 1, fc=ORANGE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.xlim([-1, 7])\n",
    "plt.ylim([-1, 2])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], FIGSIZE[1]*2))\n",
    "ax = plt.gca()\n",
    "t = np.linspace(.1, .9, 9)\n",
    "plt.vlines(t, 0, 1., linestyles='dashed', alpha=.3, zorder=-1)\n",
    "\n",
    "vc = .9\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for x, word in zip(t, words):\n",
    "    ax.text(x, vc, word, {'family': 'monospace', 'size': 12}, ha='center', va='center')\n",
    "\n",
    "vc = .7\n",
    "signal = .08*np.sin(2.4*t*np.pi) + vc\n",
    "plt.plot(t, signal, 'k.', ms=10)\n",
    "plt.vlines(t, [s if s > vc else vc for s in signal],\n",
    "           [s if s < vc else vc for s in signal], lw=1.2) \n",
    "\n",
    "vc = .5\n",
    "a, _ = librosa.load('data/1_A.wav')\n",
    "N = a.shape[0]\n",
    "for x in t:\n",
    "    frame = a[(x - .1)*N:(x + .1)*N]\n",
    "    spectrum = np.abs(np.fft.rfft(frame))\n",
    "    spectrum = spectrum[:spectrum.shape[0]/3]\n",
    "    spectrum = spectrum/3000.\n",
    "    plt.plot(x + spectrum, np.linspace(vc - .08, vc + .08, spectrum.shape[0]), 'k')\n",
    "\n",
    "axis = plt.axis()\n",
    "vc = .3\n",
    "w = .02\n",
    "h = .08\n",
    "dna_names = ['T', 'A', 'C', 'G']\n",
    "for x in t:\n",
    "    dna = np.zeros((4, 1))\n",
    "    n = np.random.randint(0, 4)\n",
    "    dna[n] = 1\n",
    "    plt.imshow(dna, interpolation='nearest', extent=(x - w, x + w, vc - h/2, vc + h), cmap=plt.cm.gray)\n",
    "    plt.plot((x - w, x - w, x + w, x + w, x - w), (vc - h/2, vc + h, vc + h, vc - h/2, vc - h/2), 'k')\n",
    "    ax.text(x, vc - h/2 - .01, dna_names[n], {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "plt.axis(axis)\n",
    "\n",
    "vc = .1\n",
    "for n, x in enumerate(t):\n",
    "    im = plt.imread('data/1_video/{}.png'.format(n + 1))\n",
    "    plt.imshow(im, interpolation='nearest', extent=(x - .03, x + .03, vc - .08, vc + .08))\n",
    "\n",
    "plt.xlim([0.05, 0.95])\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks([])\n",
    "plt.axis('off')\n",
    "\n",
    "vc = 0.\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for n, x in enumerate(t):\n",
    "    ax.text(x, vc, '$t_{}$'.format(n), {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "\n",
    "plt.savefig('1-example_sequences.pdf', transparent=True, bbox_inches='tight', pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "match_length = 100\n",
    "crop = match_length/5\n",
    "def random_walk(N):\n",
    "    return np.cumsum(np.random.random_integers(-1, 1, N))/np.log(N)\n",
    "def random_sine(N):\n",
    "    return np.sin(np.linspace(0, 5*np.pi, N)*np.random.uniform(.9, 1.1) + np.random.uniform(0, 2*np.pi))\n",
    "\n",
    "match = random_sine(match_length + match_length/10)\n",
    "query = np.interp(np.arange(match_length),\n",
    "                  np.arange(match_length + match_length/10),\n",
    "                  match + .5*random_walk(match_length + match_length/10))\n",
    "match = match[match_length/10:] + .5*random_walk(match_length)\n",
    "match = (match - match.mean())/match.std()\n",
    "query = (query - query.mean())/query.std()\n",
    "\n",
    "D = np.subtract.outer(match, query[crop/2:-crop/2])**2\n",
    "p, q, score = djitw.dtw(D, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = 3\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(query - query.max(), BLUE, lw=2)\n",
    "\n",
    "for n in range(0, match_length, ds) + [match_length - 1]:\n",
    "    plt.plot([n, n], [match[n] - match.min(), query[n] - query.max()], 'k:', lw=2)\n",
    "    \n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_unwarped.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(np.arange(crop/2, match_length - crop/2),\n",
    "         query[crop/2:-crop/2] - query[crop/2:-crop/2].max(), BLUE, lw=2)\n",
    "\n",
    "for p_n, q_n in zip(p[::ds], q[::ds]):\n",
    "    \n",
    "    plt.plot([p_n, q_n + crop/2],\n",
    "             [match[p_n] - match.min(), query[crop/2:-crop/2][q_n] - query[crop/2:-crop/2].max()],\n",
    "             'k:', lw=2)\n",
    "\n",
    "plt.plot([p[-1], q[-1] + crop/2],\n",
    "         [match[p[-1]] - match.min(), query[crop/2:-crop/2][q[-1]] - query[crop/2:-crop/2].max()],\n",
    "         'k:', lw=2)\n",
    "\n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_warped.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal1 = np.array([509, 113, -229, 253, -96, -195, 180, -303, -361, 17,\n",
    "                    -13, 242, 14, -230, 300, 89, -112, -236, -298])\n",
    "signal2 = np.array([543, 401, 122, -288, 62, 259, 180, -72, -336, 10,\n",
    "                    223, 263, 35, -345, 68, 400, 38, -109, -301])\n",
    "q = [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18]\n",
    "p = [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18]\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(signal1, lw=2, c=BLUE)\n",
    "plt.plot(signal2 + 1000, lw=2, c=GREEN)\n",
    "for p_n, q_n in zip(p, q):\n",
    "    plt.plot([p_n, q_n],  [signal1[p_n], signal2[q_n] + 1000], 'k:', lw=2)\n",
    "ax = plt.gca()\n",
    "ax.get_yaxis().set_visible(False)\n",
    "sns.despine(left=True)\n",
    "plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "plt.xlim([-.1, 18.1])\n",
    "plt.savefig('2-example_dtw_sequences.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "dist = scipy.spatial.distance.cdist(signal1.reshape(-1, 1), signal2.reshape(-1, 1))\n",
    "plt.imshow(dist, cmap=plt.cm.hot, interpolation='nearest')\n",
    "axis = plt.axis()\n",
    "for x, y in zip(q, p):\n",
    "    plt.plot([x - .5, x - .5, x + .5, x + .5, x - .5], [y - .5, y + .5, y + .5, y - .5, y - .5], 'w')\n",
    "plt.axis(axis)\n",
    "plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "plt.yticks(range(0, 19, 3), range(1, 20, 3))\n",
    "plt.savefig('2-example_dtw_matrix.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALIGNMENT_SEARCH_PATH = '/Users/craffel/Documents/projects/alignment-search/'\n",
    "sys.path.append(ALIGNMENT_SEARCH_PATH)\n",
    "import corrupt_midi\n",
    "import create_data\n",
    "import find_best_aligners\n",
    "import db_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "def compute_cqt(audio_data):\n",
    "    \"\"\" Compute the log-magnitude L2 normalized CQT \"\"\"\n",
    "    cqt, times = create_data.extract_cqt(audio_data)\n",
    "    cqt = librosa.logamplitude(cqt, ref_power=cqt.max())\n",
    "    return librosa.util.normalize(cqt, 2).T, times\n",
    "def display_cqt(cqt):\n",
    "    \"\"\" Plot a CQT with sane defaults \"\"\"\n",
    "    plt.imshow(cqt.T, aspect='auto', interpolation='nearest',\n",
    "               origin='lower', cmap=plt.cm.hot,\n",
    "               vmin=np.percentile(cqt, 1), vmax=np.percentile(cqt, 99))\n",
    "    plt.yticks(range(0, 48, 12), [librosa.midi_to_note(n) for n in range(36, 36 + 48, 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "# Grab a MIDI file from the clean MIDIs we used in this experiment\n",
    "midi_file = os.path.join(ALIGNMENT_SEARCH_PATH, 'data/mid/Come as You Are.mid')\n",
    "# Parse the MIDI file with pretty_midi\n",
    "midi_object = pretty_midi.PrettyMIDI(midi_file)\n",
    "\n",
    "# For illustration, we'll plot a CQT of the MIDI object\n",
    "# before and after corruptions.\n",
    "plt.figure(figsize=FIGSIZE_FLAT)\n",
    "original_cqt, original_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "display_cqt(original_cqt)\n",
    "#plt.title('Original MIDI CQT')\n",
    "plt.savefig('3-original_cqt.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# This is the wrapper function to apply all of the corruptions \n",
    "# defined in corrupt_midi\n",
    "adjusted_times,  diagnostics = corrupt_midi.corrupt_midi(\n",
    "    midi_object, original_times,\n",
    "    # This defines the extent to which time will be warped\n",
    "    warp_std=20,\n",
    "    # These define how likely we are to crop out sections\n",
    "    # We'll set them to 1 and 0 here for illustration; in the \n",
    "    # paper they are adjusted according to the desired corruption level\n",
    "    start_crop_prob=0., end_crop_prob=0., middle_crop_prob=1.,\n",
    "    # The likelihood that each instrument is removed\n",
    "    remove_inst_prob=.5,\n",
    "    # The likelihood that an instrument's program number is changed\n",
    "    change_inst_prob=1.,\n",
    "    # The standard deviation of velocity adjustment\n",
    "    velocity_std=1.)\n",
    "\n",
    "# Now, we can plot the CQT after corruptions.\n",
    "plt.figure(figsize=FIGSIZE_FLAT)\n",
    "corrupted_cqt, corrupted_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "display_cqt(corrupted_cqt)\n",
    "plt.xlabel('Frame')\n",
    "#plt.title('After corruption')\n",
    "plt.savefig('3-corrupted_cqt.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# We can also plot the timing offset, which we will try to reverse\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(original_times, original_times - adjusted_times, BLUE, lw=2)\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.xlabel('Original time')\n",
    "plt.ylabel('Offset from original time')\n",
    "plt.savefig('3-warping.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute a pairwise distance matrix of the original and corrupted CQTs\n",
    "distance_matrix = scipy.spatial.distance.cdist(\n",
    "    original_cqt, corrupted_cqt, 'sqeuclidean')\n",
    "# Compute the lowest-cost path via DTW with \"golden standard\" parameters\n",
    "p, q, score = djitw.dtw(\n",
    "    distance_matrix, .96, np.median(distance_matrix), inplace=0)\n",
    "\n",
    "# Plot the aligned corrupted times and ground-truth times\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(original_times[p], original_times[p] - adjusted_times[p], BLUE, lw=2)\n",
    "plt.plot(original_times[p], original_times[p] - corrupted_times[q], GREEN, lw=2)\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.legend(['Ground-truth offset', 'Fixed corrupted offset'], loc='upper left')\n",
    "plt.xlabel('Original time')\n",
    "plt.ylabel('Offset from original time')\n",
    "plt.savefig('3-warping_corrected.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# Compute the absolute error, clipped to within .5 seconds\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "error = np.abs(np.clip(\n",
    "    corrupted_times[q] - adjusted_times[p], -.5, .5))\n",
    "plt.plot(original_times[p], error, BLUE, lw=2)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correction error')\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.savefig('3-correction_error.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the results from the parameter search experiment\n",
    "params, objectives = db_utils.get_experiment_results(\n",
    "    os.path.join(ALIGNMENT_SEARCH_PATH, 'results/parameter_experiment_gp/*.json'))\n",
    "# Truncate to the top 20 results\n",
    "good = np.argsort(objectives)[:10]\n",
    "params = [params[n] for n in good]\n",
    "objectives = [objectives[n] for n in good]\n",
    "# Pretty-print using tabulate\n",
    "for param, objective in zip(params, objectives):\n",
    "    param['objective'] = objective\n",
    "header_names = collections.OrderedDict([\n",
    "    ('add_pen', '$\\phi$ Median Scale'),\n",
    "    ('standardize', 'Standardize?'),\n",
    "    ('gully', 'Gully $g$'),\n",
    "    ('objective', 'Mean Error')])\n",
    "def yes_no(x):\n",
    "    if isinstance(x, bool):\n",
    "        if x:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    else:\n",
    "        return x\n",
    "print tabulate.tabulate([collections.OrderedDict([(k, yes_no(p[k])) for k in header_names]) for p in params],\n",
    "                        headers=header_names, tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all confidence reporting experiment trials\n",
    "trials = []\n",
    "for trial_file in glob.glob(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/confidence_experiment/*.json')):\n",
    "    with open(trial_file) as f:\n",
    "        trials.append(json.load(f))\n",
    "# Retrieve the lowest-achieved mean absolute error\n",
    "best_easy_error = objectives[0]\n",
    "# Retrieve the confidence reporting trial for this system\n",
    "best_trial = [t for t in trials\n",
    "               if np.allclose(np.mean(t['results']['easy_errors']),\n",
    "                              best_easy_error)][0]\n",
    "# Retrieve the results from this trial\n",
    "best_result = best_trial['results']\n",
    "\n",
    "# Plot a scatter plot of mean alignment error vs. confidence score\n",
    "errors = np.array(best_result['hard_errors'] + best_result['easy_errors'])\n",
    "scores = np.array(best_result['hard_penalty_len_norm_mean_norm_scores'] +\n",
    "                  best_result['easy_penalty_len_norm_mean_norm_scores'])\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.scatter(errors, scores, marker='+', c='black', alpha=.3, s=40)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.ylim(0., 1.1)\n",
    "plt.xlim(.9*np.min(errors), np.max(errors)*1.1)\n",
    "plt.xlabel('Alignment error')\n",
    "plt.ylabel('Normalized DTW distance')\n",
    "plt.savefig('3-correlation.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/alignment_ratings.csv')) as f:\n",
    "    reader = csv.reader(f)\n",
    "    # Cast each entry in each row to the correct type\n",
    "    ratings = [[int(alignment_id), int(rating), np.clip(2*(1 - float(score)), 0, 1), note]\n",
    "               for alignment_id, rating, score, note in reader]\n",
    "\n",
    "# We made notes about each alignment, too.\n",
    "# Here are all the alignments where a transcription was matched to a remix\n",
    "remixes = [r[1:] for r in ratings if ('remix' in r[-1].lower())]\n",
    "remixes.sort(key = lambda x: -x[1])\n",
    "print tabulate.tabulate(remixes, headers=['Rating', 'Confidence Score', 'Note'], tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a histogram for each rating\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "data = [np.array([r[2] for r in ratings if r[1] == n]) for n in [1, 2, 3, 4, 5]]\n",
    "violins = plt.violinplot(\n",
    "    data, showextrema=False, showmeans=False,\n",
    "    widths=[float(len(d))/max(len(d) for d in data) for d in data])\n",
    "patches = plt.boxplot(data, showmeans=False, showcaps=False, showfliers=False, \n",
    "                      patch_artist=True, widths=.1)\n",
    "for line in patches['whiskers']:\n",
    "    line.set_visible(False)\n",
    "for box in patches['boxes']:\n",
    "    box.set_facecolor('None')\n",
    "    box.set_alpha(.5)\n",
    "    box.set_joinstyle('round')\n",
    "    box.set_facecolor('w')\n",
    "    box.set_edgecolor('k')\n",
    "for line in patches['medians']:\n",
    "    line.set_color('black')\n",
    "for body in violins['bodies']:\n",
    "    body.set_alpha(.8)\n",
    "for n in [0, 1]:\n",
    "    violins['bodies'][n].set_facecolor(BLUE)\n",
    "for n in [2, 3, 4]:\n",
    "    violins['bodies'][n].set_facecolor(GREEN)\n",
    "plt.xticks(\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5])\n",
    "    #['Wrong song', 'Bad alignment', 'Sloppy', 'Embellishments', 'Perfect'],\n",
    "    #rotation=20)\n",
    "plt.xlim([.5, 5.5])\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Confidence score')\n",
    "plt.legend(handles=[matplotlib.patches.Patch(color=BLUE, label='Incorrect'),\n",
    "                    matplotlib.patches.Patch(color=GREEN, label='Correct')],\n",
    "           loc='upper left')\n",
    "plt.ylim(-.03, 1.03)\n",
    "plt.savefig('3-violin.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
