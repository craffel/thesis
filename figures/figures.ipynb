{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import midi\n",
    "import matplotlib.patches\n",
    "import matplotlib\n",
    "import djitw\n",
    "import scipy.spatial\n",
    "import librosa\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import tabulate\n",
    "import ujson as json\n",
    "import collections\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_style({'grid.linewidth': 1.3})\n",
    "matplotlib.rc('font',**{'size':13, 'family':'Open Sans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing colors\n",
    "BLUE = '#1a6396'\n",
    "GREEN = '#59dd97'\n",
    "ORANGE = '#E8B71A'\n",
    "GREY = '#DFDFDF'\n",
    "RED = '#DB3340'\n",
    "TAN = '#F7EAC8'\n",
    "FIGSIZE = (9, 6)\n",
    "FIGSIZE_FLAT = (9, 2)\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.gca().add_patch(plt.Rectangle((-1, -1), 8, 1.5, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((0, 0), 1, 1, fc=BLUE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((1, 0), 1, 1, fc=GREEN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((2, 0), 1, 1, fc=GREY, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((3, 0), 1, 1, fc=RED, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((4, 0), 1, 1, fc=ORANGE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.xlim([-1, 7])\n",
    "plt.ylim([-1, 2])\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], FIGSIZE[1]*2))\n",
    "ax = plt.gca()\n",
    "t = np.linspace(.1, .9, 9)\n",
    "plt.vlines(t, 0, 1., linestyles='dashed', alpha=.3, zorder=-1)\n",
    "\n",
    "vc = .9\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for x, word in zip(t, words):\n",
    "    ax.text(x, vc, word, {'family': 'monospace', 'size': 12}, ha='center', va='center')\n",
    "\n",
    "vc = .7\n",
    "signal = .08*np.sin(2.4*t*np.pi) + vc\n",
    "plt.plot(t, signal, 'k.', ms=10)\n",
    "plt.vlines(t, [s if s > vc else vc for s in signal],\n",
    "           [s if s < vc else vc for s in signal], lw=1.2) \n",
    "\n",
    "vc = .5\n",
    "a, _ = librosa.load('data/1_A.wav')\n",
    "N = a.shape[0]\n",
    "for x in t:\n",
    "    frame = a[(x - .1)*N:(x + .1)*N]\n",
    "    spectrum = np.abs(np.fft.rfft(frame))\n",
    "    spectrum = spectrum[:spectrum.shape[0]/3]\n",
    "    spectrum = spectrum/3000.\n",
    "    plt.plot(x + spectrum, np.linspace(vc - .08, vc + .08, spectrum.shape[0]), 'k')\n",
    "\n",
    "axis = plt.axis()\n",
    "vc = .3\n",
    "w = .02\n",
    "h = .08\n",
    "dna_names = ['T', 'A', 'C', 'G']\n",
    "for x in t:\n",
    "    dna = np.zeros((4, 1))\n",
    "    n = np.random.randint(0, 4)\n",
    "    dna[n] = 1\n",
    "    plt.imshow(dna, interpolation='nearest', extent=(x - w, x + w, vc - h/2, vc + h), cmap=plt.cm.gray)\n",
    "    plt.plot((x - w, x - w, x + w, x + w, x - w), (vc - h/2, vc + h, vc + h, vc - h/2, vc - h/2), 'k')\n",
    "    ax.text(x, vc - h/2 - .01, dna_names[n], {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "plt.axis(axis)\n",
    "\n",
    "vc = .1\n",
    "for n, x in enumerate(t):\n",
    "    im = plt.imread('data/1_video/{}.png'.format(n + 1))\n",
    "    plt.imshow(im, interpolation='nearest', extent=(x - .03, x + .03, vc - .08, vc + .08))\n",
    "\n",
    "plt.xlim([0.05, 0.95])\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks([])\n",
    "plt.axis('off')\n",
    "\n",
    "vc = 0.\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for n, x in enumerate(t):\n",
    "    ax.text(x, vc, '$t_{}$'.format(n), {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "\n",
    "plt.savefig('1-example_sequences.pdf', bbox_inches='tight', pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "match_length = 100\n",
    "crop = match_length/5\n",
    "def random_walk(N):\n",
    "    return np.cumsum(np.random.random_integers(-1, 1, N))/np.log(N)\n",
    "def random_sine(N):\n",
    "    return np.sin(np.linspace(0, 5*np.pi, N)*np.random.uniform(.9, 1.1) + np.random.uniform(0, 2*np.pi))\n",
    "\n",
    "match = random_sine(match_length + match_length/10)\n",
    "query = np.interp(np.arange(match_length),\n",
    "                  np.arange(match_length + match_length/10),\n",
    "                  match + .5*random_walk(match_length + match_length/10))\n",
    "match = match[match_length/10:] + .5*random_walk(match_length)\n",
    "match = (match - match.mean())/match.std()\n",
    "query = (query - query.mean())/query.std()\n",
    "\n",
    "D = np.subtract.outer(match, query[crop/2:-crop/2])**2\n",
    "p, q, score = djitw.dtw(D, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = 3\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(query - query.max(), BLUE, lw=2)\n",
    "\n",
    "for n in range(0, match_length, ds) + [match_length - 1]:\n",
    "    plt.plot([n, n], [match[n] - match.min(), query[n] - query.max()], 'k:', lw=2)\n",
    "    \n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_unwarped.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(np.arange(crop/2, match_length - crop/2),\n",
    "         query[crop/2:-crop/2] - query[crop/2:-crop/2].max(), BLUE, lw=2)\n",
    "\n",
    "for p_n, q_n in zip(p[::ds], q[::ds]):\n",
    "    \n",
    "    plt.plot([p_n, q_n + crop/2],\n",
    "             [match[p_n] - match.min(), query[crop/2:-crop/2][q_n] - query[crop/2:-crop/2].max()],\n",
    "             'k:', lw=2)\n",
    "\n",
    "plt.plot([p[-1], q[-1] + crop/2],\n",
    "         [match[p[-1]] - match.min(), query[crop/2:-crop/2][q[-1]] - query[crop/2:-crop/2].max()],\n",
    "         'k:', lw=2)\n",
    "\n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_warped.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            for o in xrange(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n",
    "\n",
    "def label(ax, x, y, text, label_size=30, **kwargs):          \n",
    "    plt.text(x, y, text, {'size': label_size},\n",
    "             va='center', ha='center', zorder=10, **kwargs)\n",
    "\n",
    "def heaviside(ax, left, right, bottom, top):\n",
    "    middle = left + (right - left)/2.\n",
    "    for x, y in zip([[left, middle], [middle, middle], [middle, right]], \n",
    "                    [[bottom, bottom], [bottom, top], [top, top]]):\n",
    "        line = plt.Line2D(x, y, c='k', lw=2, zorder=10)\n",
    "        ax.add_artist(line)\n",
    "\n",
    "plt.figure(figsize=(FIGSIZE[0], (1 - .16)*FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "draw_neural_net(ax, .1, .9, .0, 1., [3, 1])\n",
    "\n",
    "label(ax, .1, .83333, '$x[1]$')\n",
    "label(ax, .1, .5, '$x[2]$')\n",
    "label(ax, .1, .16666, '$x[3]$')\n",
    "\n",
    "label(ax, .5, .71, '$w[1]$', rotation=-24)\n",
    "label(ax, .5, .535, '$w[2]$')\n",
    "label(ax, .5, .375, '$w[3]$', rotation=24)\n",
    "\n",
    "b_coords = (.6, .2)\n",
    "circle = plt.Circle(b_coords, 1./3./4.,\n",
    "                    color='w', ec='k', zorder=4)\n",
    "plt.gca().add_artist(circle)\n",
    "label(ax, b_coords[0], b_coords[1], '$b$', 36)\n",
    "line = plt.Line2D([b_coords[0], .9], [b_coords[1], .5], c='k')\n",
    "ax.add_artist(line)\n",
    "\n",
    "heaviside(ax, .842, .958, .46, .54)\n",
    "\n",
    "plt.ylim([.08, .92])\n",
    "plt.axis('off')\n",
    "plt.savefig('2-perceptron.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], .71*FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "\n",
    "circle_radius = .04\n",
    "circle_spacing = .09\n",
    "\n",
    "def circle_grid(ax, size, left, bottom, color='w', zorder=4, **kwargs):\n",
    "    for x in range(size[0]):\n",
    "        for y in range(size[1]):\n",
    "            circle = plt.Circle((x*circle_spacing + left, y*circle_spacing + bottom),\n",
    "                                circle_radius, color=color, ec='k', zorder=zorder - x - y, **kwargs)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "input_left, input_bottom = .05, .05\n",
    "output_left, output_bottom = .65, input_bottom + 3.85*circle_spacing\n",
    "circle_grid(ax, (6, 6), input_left, input_bottom)\n",
    "circle_grid(ax, (4, 4), output_left, output_bottom, color='none', zorder=35, alpha=.3)\n",
    "circle_grid(ax, (3, 3), input_left + 2*circle_spacing, input_bottom + 2*circle_spacing, GREEN, zorder=30)\n",
    "circle_grid(ax, (1, 1), output_left + 2*circle_spacing, output_bottom + 2*circle_spacing, GREEN, zorder=40)\n",
    "\n",
    "ffdeg = circle_radius*np.sqrt(2)/2\n",
    "for x in range(3):\n",
    "    for y in range(3):\n",
    "        line = plt.Line2D([input_left + 2*circle_spacing + x*circle_spacing,\n",
    "                           output_left + 2*circle_spacing],\n",
    "                          [input_bottom + 2*circle_spacing + y*circle_spacing,\n",
    "                           output_bottom + 2*circle_spacing], c='k', zorder=30 - x - y - 1)\n",
    "        ax.add_artist(line)\n",
    "plt.axis([0, .97, 0, .71])\n",
    "plt.axis('off')\n",
    "plt.savefig('2-convolution.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "def f(x):\n",
    "    return x**2\n",
    "def df(x):\n",
    "    return 2*x\n",
    "x = np.linspace(-1, 1, 100)\n",
    "x_init = .7\n",
    "\n",
    "for n, lr in enumerate([1.035, .9, .4, .08]):\n",
    "    plt.subplot(2, 2, n + 1)\n",
    "    plt.plot(x, f(x), BLUE, lw=2)\n",
    "    x_current = x_init\n",
    "    for i in range(5):\n",
    "        x_new = x_current - lr*df(x_current)\n",
    "        plt.plot([x_current, x_new], [f(x_current), f(x_new)], 'k:')\n",
    "        plt.plot([x_current, x_new], [f(x_current), f(x_new)], 'k.', ms=10)\n",
    "        x_current = x_new\n",
    "    plt.ylim(-.01, 1.)\n",
    "    plt.axis('off')\n",
    "plt.savefig('2-learning_rate.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bayes_opt\n",
    "import matplotlib.gridspec\n",
    "\n",
    "def target(x):\n",
    "    return (-3*(x - .7)**2) + .3*(np.sin(10*x**2) + 3)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = target(x)\n",
    "\n",
    "bo = bayes_opt.BayesianOptimization(target, {'x': (0, 1)}, False)\n",
    "\n",
    "gp_params = {'corr': 'squared_exponential'}\n",
    "bo.initialize(dict((target(n), {'x': n}) for n in [.05, .4, .7, .97]))\n",
    "bo.maximize(init_points=0, n_iter=0, acq='ei', **gp_params)\n",
    "\n",
    "def posterior(bo, xmin=-2, xmax=10):\n",
    "    xmin, xmax = 0, 1\n",
    "    bo.gp.fit(bo.X, bo.Y)\n",
    "    mu, sigma2 = bo.gp.predict(np.linspace(xmin, xmax, 1000).reshape(-1, 1), eval_MSE=True)\n",
    "    return mu, np.sqrt(sigma2)\n",
    "\n",
    "fig = plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "gs = matplotlib.gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
    "ax = plt.subplot(gs[0])\n",
    "\n",
    "mu, sigma = posterior(bo)\n",
    "ax.plot(x, y, BLUE, linewidth=2)\n",
    "ax.plot(bo.X.flatten(), bo.Y, 'k.', markersize=20)\n",
    "\n",
    "ax.fill(np.concatenate([x, x[::-1]]), \n",
    "          np.concatenate([mu - sigma, (mu + sigma)[::-1]]),\n",
    "          fc=GREY, ec='None')\n",
    "ax.axis('off')\n",
    "ax.set_title('Objective')\n",
    "ax.set_ylim([y.min(), y.max()*1.1])\n",
    "\n",
    "ax.set_xlim((0, 1))\n",
    "\n",
    "ax = plt.subplot(gs[1])\n",
    "utility = bo.util.utility(x.reshape((-1, 1)), bo.gp, 0)\n",
    "ax.fill_between(x, utility, facecolor=GREEN, edgecolor='none')\n",
    "ax.set_xlim((0, 1))\n",
    "ax.axis('off')\n",
    "ax.set_title('Expected Improvement')\n",
    "plt.savefig('2-bayesian_optimization.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duration = 5\n",
    "a, fs = librosa.load('data/2_song.mp3', offset=.25, duration=duration)\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plot_fs = 1000\n",
    "plt.plot(np.linspace(0, duration, duration*plot_fs), librosa.resample(a, fs, plot_fs), BLUE, lw=.2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1])\n",
    "plt.savefig('2-audio_signal.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "\n",
    "tbl_f = np.asarray(\n",
    "    [20, 25, 31.5, 40, 50, 63, 80, 100, 125, 160, 200, 250, 315, 400,\n",
    "     500, 630, 800, 1000, 1250, 1600, 2000, 2500, 3150, 4000, 5000, 6300,\n",
    "     8000, 10000, 12500])\n",
    "tbl_alpha_f = np.asarray(\n",
    "    [0.532, 0.506, 0.480, 0.455, 0.432, 0.409, 0.387, 0.367, 0.349, 0.330,\n",
    "     0.315, 0.301, 0.288, 0.276, 0.267, 0.259, 0.253, 0.250, 0.246, 0.244,\n",
    "     0.243, 0.243, 0.243, 0.242, 0.242, 0.245, 0.254, 0.271, 0.301])\n",
    "tbl_L_U = np.asarray(\n",
    "    [-31.6, -27.2, -23.0, -19.1, -15.9, -13.0, -10.3, -8.1, -6.2, -4.5,\n",
    "     -3.1, -2.0, -1.1, -0.4, 0.0, 0.3, 0.5, 0.0, -2.7, -4.1, -1.0, 1.7,\n",
    "     2.5, 1.2, -2.1, -7.1, -11.2, -10.7, -3.1])\n",
    "tbl_T_f = np.asarray(\n",
    "    [78.5, 68.7, 59.5, 51.1, 44.0, 37.5, 31.5, 26.5, 22.1, 17.9, 14.4,\n",
    "     11.4, 8.6, 6.2, 4.4, 3.0, 2.2, 2.4, 3.5, 1.7, -1.3, -4.2, -6.0, -5.4,\n",
    "     -1.5, 6.0, 12.6, 13.9, 12.3])\n",
    "\n",
    "def iso226_spl_contour(f, L_N=40):\n",
    "    A_f = (4.47E-3*(10.0**(0.025*L_N)-1.15) +\n",
    "           (0.4*10.0**((tbl_T_f+tbl_L_U)/10.0-9.0))**tbl_alpha_f)\n",
    "    return scipy.interpolate.InterpolatedUnivariateSpline(\n",
    "        tbl_f, (10.0/tbl_alpha_f)*np.log10(A_f) - tbl_L_U + 94.0, k=3)(f)\n",
    "\n",
    "f = np.logspace(np.log10(20), np.log10(12500), 100, base=10)\n",
    "l = iso226_spl_contour(f)\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.semilogx(f, l, BLUE, lw=2)\n",
    "plt.xlim([15, 15000])\n",
    "plt.xticks([30, 100, 300, 1000, 3000, 10000],\n",
    "           [30, 100, 300, 1000, 3000, 10000])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Sound Pressure Level (dB)')\n",
    "plt.savefig('2-equal_loudness.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piano = pretty_midi.PrettyMIDI()\n",
    "i = pretty_midi.Instrument(0, False)\n",
    "i.notes.append(pretty_midi.Note(100, 48, 0., 1.))\n",
    "piano.instruments.append(i)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(piano.fluidsynth(8000)[400:600], BLUE, lw=2)\n",
    "\n",
    "guitar = pretty_midi.PrettyMIDI()\n",
    "i = pretty_midi.Instrument(41, False)\n",
    "i.notes.append(pretty_midi.Note(100, 48, 0., 1.))\n",
    "piano.instruments.append(i)\n",
    "plt.plot(piano.fluidsynth(8000)[400:600], GREEN, lw=2)\n",
    "sns.despine()\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1])\n",
    "plt.xticks(np.arange(0, 201, 50), np.arange(0, 201, 50)/8.)\n",
    "plt.savefig('2-timbres.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "A = np.abs(np.fft.rfft(a))\n",
    "N = A.shape[0]\n",
    "#A /= N\n",
    "A = A[:5001]\n",
    "plt.xticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "           100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/N/100.).astype(int))\n",
    "plt.plot(A, BLUE, lw=.5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.savefig('2-spectrum.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = np.abs(librosa.stft(a))[:93]\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.5))\n",
    "    plt.yticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "               100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/1024./100.).astype(int))\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.savefig('2-spectrogram.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = librosa.logamplitude(A)\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.5))\n",
    "    plt.yticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "               100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/1024./100.).astype(int))\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.savefig('2-log_spectrogram.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = librosa.logamplitude(np.abs(librosa.cqt(a, fmin=librosa.midi_to_hz(36), n_bins=48, real=False)))\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.9))\n",
    "    plt.yticks(range(0, 48, 12), [librosa.midi_to_note(n) for n in range(36, 36 + 48, 12)])\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Note')\n",
    "    plt.savefig('2-cqt.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal1 = np.array([509, 113, -229, 253, -96, -195, 180, -303, -361, 17,\n",
    "                    -13, 242, 14, -230, 300, 89, -112, -236, -298])\n",
    "signal2 = np.array([543, 401, 122, -288, 62, 259, 180, -72, -336, 10,\n",
    "                    223, 263, 35, -345, 68, 400, 38, -109, -301])\n",
    "q = [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18]\n",
    "p = [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18]\n",
    "with sns.axes_style('ticks'):\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    plt.plot(signal1, lw=2, c=BLUE)\n",
    "    plt.plot(signal1, '.', ms=10, c=BLUE)\n",
    "    plt.plot(signal2 + 1000, lw=2, c=GREEN)\n",
    "    plt.plot(signal2 + 1000, '.', ms=10, c=GREEN)\n",
    "    for p_n, q_n in zip(p, q):\n",
    "        plt.plot([p_n, q_n],  [signal1[p_n], signal2[q_n] + 1000], 'k:', lw=2)\n",
    "    ax = plt.gca()\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    sns.despine(left=True)\n",
    "    plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.xlim([-.1, 18.1])\n",
    "    plt.savefig('2-example_dtw_sequences.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    dist = scipy.spatial.distance.cdist(signal1.reshape(-1, 1), signal2.reshape(-1, 1))\n",
    "    plt.imshow(dist, cmap=plt.cm.hot, interpolation='nearest')\n",
    "    axis = plt.axis()\n",
    "    for x, y in zip(q, p):\n",
    "        plt.plot([x - .5, x - .5, x + .5, x + .5, x - .5], [y - .5, y + .5, y + .5, y - .5, y - .5], 'w')\n",
    "    plt.axis(axis)\n",
    "    plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.yticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.savefig('2-example_dtw_matrix.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "with open('data/3-statistics.pkl') as f:\n",
    "    statistics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "statistics = statistics[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def uniform_hist(data, bins, ax, **kwargs):\n",
    "    heights, _ = np.histogram(data, bins)\n",
    "    ax.bar(left=np.arange(len(bins) - 1) - .5, height=heights,\n",
    "           width=1, bottom=0, **kwargs)\n",
    "    return heights\n",
    "\n",
    "def pretty_hist(data, bins, fc, ax):\n",
    "    \"\"\" Utility method for plotting a nice histogram \"\"\"\n",
    "    # Make it so that all points beyond the bin range get put in the last bin\n",
    "    data = np.array(data)\n",
    "    data[data > bins[-1]] = bins[-1] - 1e-10\n",
    "    # Plot histogram, with specific coloring and axis-alignment\n",
    "    heights = uniform_hist(data, bins, ax, fc=fc, alpha=.8)\n",
    "    # Remove spines from plot\n",
    "    sns.despine()\n",
    "    # Add grid to y axis\n",
    "    ax.yaxis.grid()\n",
    "    # Set the plotting range to fit the histogram exactly\n",
    "    bin_spacing = 1.\n",
    "    ax.set_xlim(-bin_spacing/2., len(bins) - 1 - bin_spacing/2.)\n",
    "    return heights\n",
    "\n",
    "def divide_yticklabels(ax, divisor=1000):\n",
    "    \"\"\" Utility method to scale down all y tick labels \"\"\"\n",
    "    ax.set_yticklabels([int(float(t)/divisor)\n",
    "                        if (float(t)/divisor).is_integer()\n",
    "                        else float(t)/divisor\n",
    "                        for t in ax.get_yticks()])\n",
    "\n",
    "def split_hist(data, bin_edges, high_bin_indices, fc):\n",
    "    \"\"\" Plot a histogram where one or more bins have very large values \"\"\"\n",
    "    # Make high_bin_indices a list if an int was passed\n",
    "    if isinstance(high_bin_indices, int):\n",
    "        high_bin_indices = [high_bin_indices]\n",
    "    # Create 2-row, 1-col subplot where the upper sublot is 1/4 the height\n",
    "    # The upper subplot will be the tops of the very large bins; lower will be the rest\n",
    "    gs = matplotlib.gridspec.GridSpec(2, 1, width_ratios=[1,], height_ratios=[1, 4])\n",
    "    # Set the spacing between subplots to .1\n",
    "    gs.update(hspace=0.1)\n",
    "    # Grab axes handles\n",
    "    ax = plt.subplot(gs[0])\n",
    "    ax2 = plt.subplot(gs[1])\n",
    "    # Plot pretty histograms both for the \"upper\" and \"lower\" parts of the split\n",
    "    heights = pretty_hist(data, bin_edges, fc, ax)\n",
    "    pretty_hist(data, bin_edges, fc, ax2)\n",
    "    low_min = 0\n",
    "    # Compute the height of the largest bin _not_ in high_bin_indices\n",
    "    low_max = 1.1*max(heights[n] for n in range(len(bin_edges) - 1)\n",
    "                      if n not in high_bin_indices)\n",
    "    low_range = low_max - low_min\n",
    "    # Compute the height of the smallest bin in high_bin_indices\n",
    "    high_min = .9*min(heights[n] for n in high_bin_indices)\n",
    "    # Compute the height of the highest bin in high_bin_indices\n",
    "    high_max = 1.1*max(heights[n] for n in high_bin_indices)\n",
    "    # Set the Y plotting range according to the above.  This will crop things.\n",
    "    ax.set_ylim(high_min, high_max)\n",
    "    ax2.set_ylim(low_min, low_max)\n",
    "    # Hide the spines between ax and ax2\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.tick_params(labeltop='off')\n",
    "    ax2.xaxis.tick_bottom()\n",
    "\n",
    "    # Compute the spacing between y-ticks on the lower plot\n",
    "    lowtick_spacing = np.diff(ax2.get_yticks())[0]\n",
    "    # Create a single tick on the upper plot, rounded to the same spacing as lower plot\n",
    "    ax.set_yticks([int(lowtick_spacing)*int((high_min + high_max)/(2*lowtick_spacing))])\n",
    "\n",
    "    # X-axis start of clip lines (relative to [0, 1])\n",
    "    start = -.015\n",
    "    # Compute proportion of x-axis covered by last high_bin_indices (+ .015)\n",
    "    end = (high_bin_indices[-1] + 1)/float(len(bin_edges) - 1) + .015\n",
    "    # Plot the lines, allowing for it to expand outside of the axis\n",
    "    ax.plot([start, end], [0., 0.], transform=ax.transAxes, color='k', clip_on=False)\n",
    "    ax2.plot([start, end], [1., 1.], transform=ax2.transAxes, color='k', clip_on=False)\n",
    "\n",
    "    # Convert count to thousands\n",
    "    divide_yticklabels(ax)\n",
    "    divide_yticklabels(ax2)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    pretty_hist([s['n_instruments'] for s in statistics],\n",
    "                range(22), BLUE, plt.gca())\n",
    "    divide_yticklabels(plt.gca())\n",
    "    plt.ylabel('Thousands of MIDI files')\n",
    "    plt.xlabel('Number of instruments')\n",
    "    plt.savefig('3-n_instruments.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.xticks(range(0, 22, 5), range(0, 22 - 5, 5) + ['20+'])\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    split_hist([i for s in statistics for i in s['program_numbers']],\n",
    "               range(128), 0, BLUE)\n",
    "    plt.ylabel('Thousands of occurrences')\n",
    "    plt.xlabel('Program number')\n",
    "    plt.savefig('3-program_numbers.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    split_hist([len(s['tempos']) for s in statistics],\n",
    "               range(1, 12) + [30, 100, 1000], 0, GREEN)\n",
    "    plt.xticks(range(13), range(1, 11) + ['11 - 30', '31 - 100', '101+'], rotation=45, ha='center')\n",
    "    plt.ylabel('Thousands of MIDI files')\n",
    "    plt.xlabel('Number of tempo changes', labelpad=-25)\n",
    "    plt.savefig('3-n_tempos.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    pretty_hist([i for s in statistics for i in s['tempos']],\n",
    "                range(0, 260, 10), GREEN, plt.gca())\n",
    "    divide_yticklabels(plt.gca())\n",
    "    plt.xticks(range(0, len(range(0, 260, 10)), 3), range(0, 240, 30) + ['240+'], rotation=45)\n",
    "    plt.ylabel('Thousands of occurrences')\n",
    "    plt.xlabel('Tempo', labelpad=-5)\n",
    "    plt.savefig('3-tempos.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    split_hist([len(s['key_numbers']) for s in statistics],\n",
    "               range(12), [0, 1], ORANGE)\n",
    "    plt.xticks(range(11), range(10) + ['10+'])\n",
    "    plt.ylabel('Thousands of MIDI files')\n",
    "    plt.xlabel('Number of key changes')\n",
    "    plt.savefig('3-n_keys.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    fig = plt.figure(figsize=FIGSIZE)\n",
    "    split_hist([i for s in statistics for i in s['key_numbers']],\n",
    "               range(25), 0, ORANGE)\n",
    "    plt.xticks([0, 2, 4, 5, 7, 9, 11, 12, 14, 16, 17, 19, 21, 23],\n",
    "               ['C', 'D', 'E', 'F', 'G', 'A', 'B', 'c', 'd', 'e', 'f', 'g', 'a', 'b'])\n",
    "    plt.figtext(0.315, .07, 'Major', ha='center', va='center')\n",
    "    plt.figtext(0.705, .07, 'Minor', ha='center', va='center')\n",
    "    l1 = matplotlib.lines.Line2D([.14, .276], [.07, .07], c='k', transform=fig.transFigure, figure=fig)\n",
    "    l2 = matplotlib.lines.Line2D([.35, .485], [.07, .07], c='k', transform=fig.transFigure, figure=fig)\n",
    "    l3 = matplotlib.lines.Line2D([.54, .67], [.07, .07], c='k', transform=fig.transFigure, figure=fig)\n",
    "    l4 = matplotlib.lines.Line2D([.74, .88], [.07, .07], c='k', transform=fig.transFigure, figure=fig)\n",
    "    fig.lines.extend([l1, l2, l3, l4])\n",
    "    plt.ylabel('Thousands of occurrences')\n",
    "    plt.xlabel('Key', labelpad=1.5)\n",
    "    plt.savefig('3-keys.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    split_hist([len(s['time_signature_changes']) for s in statistics],\n",
    "               range(12), 1, RED)\n",
    "    plt.xticks(range(11), range(10) + ['10+'])\n",
    "    plt.ylabel('Thousands of MIDI files')\n",
    "    plt.xlabel('Number of time signature changes')\n",
    "    plt.savefig('3-n_signatures.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    # Get strings for all time signatures\n",
    "    time_signatures = ['{}/{}'.format(c.numerator, c.denominator)\n",
    "                       for s in statistics for c in s['time_signature_changes']]\n",
    "\n",
    "    # Only display the n_top top time signatures\n",
    "    n_top = 15\n",
    "    # Get the n_top top time signatures\n",
    "    top = collections.Counter(time_signatures).most_common(n_top)\n",
    "    # Create a dict mapping an integer index to the time signature string\n",
    "    top_signatures = {n: s[0] for n, s in enumerate(top)}\n",
    "    # Add an additional index for non-top signatures\n",
    "    top_signatures[n_top] = 'Other'\n",
    "    # Compute the number of non-top time signatures\n",
    "    n_other = len(time_signatures) - sum(s[1] for s in top)\n",
    "    # Create a list with each index repeated the number of times\n",
    "    # each time signature appears, to be passed to plt.hist\n",
    "    indexed_time_signatures = sum([[n]*s[1] for n, s in enumerate(top)], [])\n",
    "    indexed_time_signatures += [n_top]*n_other\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    split_hist(indexed_time_signatures, range(n_top + 2), 0, RED)\n",
    "    plt.xticks(top_signatures.keys(), top_signatures.values(), rotation=45, ha='center')\n",
    "    plt.ylabel('Thousands of occurrences')\n",
    "    plt.xlabel('Time signature', labelpad=-7)\n",
    "    plt.savefig('3-time_signatures.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALIGNMENT_SEARCH_PATH = '/Users/craffel/Documents/projects/alignment-search/'\n",
    "sys.path.append(ALIGNMENT_SEARCH_PATH)\n",
    "import corrupt_midi\n",
    "import create_data\n",
    "import find_best_aligners\n",
    "import db_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "def compute_cqt(audio_data):\n",
    "    \"\"\" Compute the log-magnitude L2 normalized CQT \"\"\"\n",
    "    cqt, times = create_data.extract_cqt(audio_data)\n",
    "    cqt = librosa.logamplitude(cqt, ref_power=cqt.max())\n",
    "    return librosa.util.normalize(cqt, 2).T, times\n",
    "def display_cqt(cqt):\n",
    "    \"\"\" Plot a CQT with sane defaults \"\"\"\n",
    "    plt.imshow(cqt.T, aspect='auto', interpolation='nearest',\n",
    "               origin='lower', cmap=plt.cm.hot,\n",
    "               vmin=np.percentile(cqt, 1), vmax=np.percentile(cqt, 99))\n",
    "    plt.yticks(range(0, 48, 12), [librosa.midi_to_note(n) for n in range(36, 36 + 48, 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "# Grab a MIDI file from the clean MIDIs we used in this experiment\n",
    "midi_file = os.path.join(ALIGNMENT_SEARCH_PATH, 'data/mid/Come as You Are.mid')\n",
    "# Parse the MIDI file with pretty_midi\n",
    "midi_object = pretty_midi.PrettyMIDI(midi_file)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    # For illustration, we'll plot a CQT of the MIDI object\n",
    "    # before and after corruptions.\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    original_cqt, original_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "    display_cqt(original_cqt)\n",
    "    #plt.title('Original MIDI CQT')\n",
    "    plt.savefig('4-original_cqt.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# This is the wrapper function to apply all of the corruptions \n",
    "# defined in corrupt_midi\n",
    "adjusted_times,  diagnostics = corrupt_midi.corrupt_midi(\n",
    "    midi_object, original_times,\n",
    "    # This defines the extent to which time will be warped\n",
    "    warp_std=20,\n",
    "    # These define how likely we are to crop out sections\n",
    "    # We'll set them to 1 and 0 here for illustration; in the \n",
    "    # paper they are adjusted according to the desired corruption level\n",
    "    start_crop_prob=0., end_crop_prob=0., middle_crop_prob=1.,\n",
    "    # The likelihood that each instrument is removed\n",
    "    remove_inst_prob=.5,\n",
    "    # The likelihood that an instrument's program number is changed\n",
    "    change_inst_prob=1.,\n",
    "    # The standard deviation of velocity adjustment\n",
    "    velocity_std=1.)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    # Now, we can plot the CQT after corruptions.\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    corrupted_cqt, corrupted_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "    display_cqt(corrupted_cqt)\n",
    "    plt.xlabel('Frame')\n",
    "    #plt.title('After corruption')\n",
    "    plt.savefig('4-corrupted_cqt.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# We can also plot the timing offset, which we will try to reverse\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(original_times, original_times - adjusted_times, BLUE, lw=2)\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.xlabel('Original time')\n",
    "plt.ylabel('Offset from original time')\n",
    "plt.savefig('4-warping.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute a pairwise distance matrix of the original and corrupted CQTs\n",
    "distance_matrix = scipy.spatial.distance.cdist(\n",
    "    original_cqt, corrupted_cqt, 'sqeuclidean')\n",
    "# Compute the lowest-cost path via DTW with \"golden standard\" parameters\n",
    "p, q, score = djitw.dtw(\n",
    "    distance_matrix, .96, np.median(distance_matrix), inplace=0)\n",
    "\n",
    "# Compute the absolute error, clipped to within .5 seconds\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "error = np.abs(np.clip(\n",
    "    corrupted_times[q] - adjusted_times[p], -.5, .5))\n",
    "plt.plot(original_times[p], error, BLUE, lw=2)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correction error')\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.ylim([-0.01, .51])\n",
    "plt.savefig('4-correction_error.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the results from the parameter search experiment\n",
    "params, objectives = db_utils.get_experiment_results(\n",
    "    os.path.join(ALIGNMENT_SEARCH_PATH, 'results/parameter_experiment_gp/*.json'))\n",
    "# Truncate to the top 20 results\n",
    "good = np.argsort(objectives)[:10]\n",
    "params = [params[n] for n in good]\n",
    "objectives = [objectives[n] for n in good]\n",
    "# Pretty-print using tabulate\n",
    "for param, objective in zip(params, objectives):\n",
    "    param['objective'] = objective\n",
    "header_names = collections.OrderedDict([\n",
    "    ('add_pen', '$\\phi$ Median Scale'),\n",
    "    ('standardize', 'Standardize?'),\n",
    "    ('gully', 'Gully $g$'),\n",
    "    ('objective', 'Mean Error')])\n",
    "def yes_no(x):\n",
    "    if isinstance(x, bool):\n",
    "        if x:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    else:\n",
    "        return x\n",
    "print tabulate.tabulate([collections.OrderedDict([(k, yes_no(p[k])) for k in header_names]) for p in params],\n",
    "                        headers=header_names, tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all confidence reporting experiment trials\n",
    "trials = []\n",
    "for trial_file in glob.glob(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/confidence_experiment/*.json')):\n",
    "    with open(trial_file) as f:\n",
    "        trials.append(json.load(f))\n",
    "# Retrieve the lowest-achieved mean absolute error\n",
    "best_easy_error = objectives[0]\n",
    "# Retrieve the confidence reporting trial for this system\n",
    "best_trial = [t for t in trials\n",
    "               if np.allclose(np.mean(t['results']['easy_errors']),\n",
    "                              best_easy_error)][0]\n",
    "# Retrieve the results from this trial\n",
    "best_result = best_trial['results']\n",
    "\n",
    "# Plot a scatter plot of mean alignment error vs. confidence score\n",
    "errors = np.array(best_result['hard_errors'] + best_result['easy_errors'])\n",
    "scores = np.array(best_result['hard_penalty_len_norm_mean_norm_scores'] +\n",
    "                  best_result['easy_penalty_len_norm_mean_norm_scores'])\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.scatter(errors, scores, marker='+', c='black', alpha=.3, s=40)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.ylim(0., 1.1)\n",
    "plt.xlim(.9*np.min(errors), np.max(errors)*1.1)\n",
    "plt.xlabel('Alignment error')\n",
    "plt.ylabel('Normalized DTW distance')\n",
    "plt.xticks([.01, .025, .05, .1, .25, .5], [.01, .025, .05, .1, .25, .5])\n",
    "plt.savefig('4-correlation.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/alignment_ratings.csv')) as f:\n",
    "    reader = csv.reader(f)\n",
    "    # Cast each entry in each row to the correct type\n",
    "    ratings = [[int(alignment_id), int(rating), np.clip(2*(1 - float(score)), 0, 1), note]\n",
    "               for alignment_id, rating, score, note in reader]\n",
    "\n",
    "# We made notes about each alignment, too.\n",
    "# Here are all the alignments where a transcription was matched to a remix\n",
    "remixes = [r[1:] for r in ratings if ('remix' in r[-1].lower())]\n",
    "remixes.sort(key = lambda x: -x[1])\n",
    "print tabulate.tabulate(remixes, headers=['Rating', 'Confidence Score', 'Note'], tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a histogram for each rating\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "data = [np.array([r[2] for r in ratings if r[1] == n]) for n in [1, 2, 3, 4, 5]]\n",
    "violins = plt.violinplot(\n",
    "    data, showextrema=False, showmeans=False,\n",
    "    widths=[float(len(d))/max(len(d) for d in data) for d in data])\n",
    "patches = plt.boxplot(data, showmeans=False, showcaps=False, showfliers=False, \n",
    "                      patch_artist=True, widths=.1)\n",
    "for line in patches['whiskers']:\n",
    "    line.set_visible(False)\n",
    "for box in patches['boxes']:\n",
    "    box.set_facecolor('None')\n",
    "    box.set_alpha(.5)\n",
    "    box.set_joinstyle('round')\n",
    "    box.set_facecolor('w')\n",
    "    box.set_edgecolor('k')\n",
    "for line in patches['medians']:\n",
    "    line.set_color('black')\n",
    "for body in violins['bodies']:\n",
    "    body.set_alpha(.8)\n",
    "for n in [0, 1]:\n",
    "    violins['bodies'][n].set_facecolor(BLUE)\n",
    "for n in [2, 3, 4]:\n",
    "    violins['bodies'][n].set_facecolor(GREEN)\n",
    "plt.xticks(\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5])\n",
    "    #['Wrong song', 'Bad alignment', 'Sloppy', 'Embellishments', 'Perfect'],\n",
    "    #rotation=20)\n",
    "plt.xlim([.5, 5.5])\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Confidence score')\n",
    "plt.legend(handles=[matplotlib.patches.Patch(color=BLUE, label='Incorrect'),\n",
    "                    matplotlib.patches.Patch(color=GREEN, label='Correct')],\n",
    "           loc='upper left')\n",
    "plt.ylim(-.03, 1.03)\n",
    "plt.savefig('4-violin.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pretty_cqt(audio_data, fs=feature_extraction.AUDIO_FS):\n",
    "    gram = np.abs(librosa.cqt(\n",
    "        audio_data, sr=fs, hop_length=feature_extraction.AUDIO_HOP,\n",
    "        fmin=librosa.midi_to_hz(feature_extraction.NOTE_START),\n",
    "        n_bins=feature_extraction.N_NOTES, real=False))\n",
    "    # Compute log amplitude\n",
    "    gram = librosa.logamplitude(gram**2, ref_power=gram.max())\n",
    "    # Transpose so that rows are samples\n",
    "    gram = gram.T\n",
    "    # and L2 normalize\n",
    "    #gram = librosa.util.normalize(gram, axis=1)\n",
    "    # and convert to float32\n",
    "    return gram.astype(np.float32)\n",
    "audio, fs = librosa.load('data/5-mmt.wav', sr=feature_extraction.AUDIO_FS)\n",
    "audio_gram = pretty_cqt(audio)\n",
    "m = pretty_midi.PrettyMIDI('data/5-mmt.mid')\n",
    "midi_audio_aligned = m.fluidsynth(feature_extraction.AUDIO_FS)\n",
    "# Adjust to the same size as audio\n",
    "if midi_audio_aligned.shape[0] > audio.shape[0]:\n",
    "    midi_audio_aligned = midi_audio_aligned[:audio.shape[0]]\n",
    "else:\n",
    "    trim_amount = audio.shape[0] - midi_audio_aligned.shape[0]\n",
    "    midi_audio_aligned = np.append(midi_audio_aligned,\n",
    "                                   np.zeros(trim_amount))\n",
    "midi_aligned_gram = pretty_cqt(midi_audio_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_brace(ax, left, right, bottom, top, beta=10., fliplr=False, flipud=False):\n",
    "    if flipud:\n",
    "        bottom, left = left, bottom\n",
    "        right, top = top, right\n",
    "    half_y = (top + bottom)/2.\n",
    "    half_range = np.linspace(bottom, half_y, 100)\n",
    "    x = (1/(1. + np.exp(beta*(half_range - bottom)))\n",
    "         + 1/(1. + np.exp(beta*(half_range - half_y))))\n",
    "    x = np.concatenate((x, x[::-1]))\n",
    "    if fliplr:\n",
    "        x = -x + 1\n",
    "    else:\n",
    "        x = x - 1\n",
    "    x = x*(right - left) + (left + right)/2.\n",
    "    if flipud:\n",
    "        ax.plot(np.linspace(bottom, top, 200), x, 'k', lw=2)\n",
    "    else:\n",
    "        ax.plot(x, np.linspace(bottom, top, 200), 'k', lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(FIGSIZE[0], FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "draw_neural_net(ax, .3, .6, .51, .79, [4, 7, 5, 3])\n",
    "ax.text(.32, .76, '$f$', ha='center', va='center', fontdict={'size': 30})\n",
    "draw_neural_net(ax, .3, .6, .21, .49, [4, 6, 7, 3])\n",
    "ax.text(.32, .46, '$g$', ha='center', va='center', fontdict={'size': 30})\n",
    "\n",
    "ax.annotate('', xy=(.15, .8),  xycoords='data',\n",
    "            xytext=(.25, .65), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .255, .285, .58, .72, 1000.)\n",
    "\n",
    "ax.annotate('', xy=(.15, .2),  xycoords='data',\n",
    "            xytext=(.25, .35), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .255, .285, .28, .42, 1000.)\n",
    "\n",
    "ax.annotate('', xy=(.65, .65),  xycoords='data',\n",
    "            xytext=(.8, .55), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=90,angleB=0,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .615, .645, .6, .7, 1000., 1)\n",
    "\n",
    "ax.annotate('', xy=(.65, .35),  xycoords='data',\n",
    "            xytext=(.8, .45), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=90,angleB=0,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .615, .645, .3, .4, 1000., 1)\n",
    "\n",
    "ax.imshow(audio_gram[500:700].T, interpolation='nearest', aspect='auto', cmap=plt.cm.hot,\n",
    "          origin='lower', extent=(0, 1, .8, 1), vmin=np.percentile(audio_gram, 15))\n",
    "ax.imshow(midi_aligned_gram[500:700].T, interpolation='nearest', aspect='auto', cmap=plt.cm.hot,\n",
    "          origin='lower', extent=(0, 1, 0, .2), vmin=np.percentile(midi_aligned_gram, 15))\n",
    "\n",
    "ax.imshow(np.array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]]), cmap=plt.cm.hot,\n",
    "          extent=(.6, 1., .46, .485), interpolation='nearest')\n",
    "\n",
    "ax.imshow(np.array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0]]), cmap=plt.cm.hot,\n",
    "          extent=(.6, 1., .51, .535), interpolation='nearest')\n",
    "\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.13, 0.001), 0.04, 0.2, alpha=.6, fc='w'))\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.13, 0.8), 0.04, 0.2, alpha=.6, fc='w'))\n",
    "\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.6, 0.46), 0.4, 0.025, fc='None', ec='k'))\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.6, 0.51), 0.4, 0.025, fc='None', ec='k'))\n",
    "\n",
    "ax.axis([0, 1, 0, 1])\n",
    "ax.axis('off')\n",
    "plt.savefig('5-hashing_schematic.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hash_a = np.array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], dtype=bool)\n",
    "hash_b = np.array([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0], dtype=bool)\n",
    "xor = np.bitwise_xor(hash_a, hash_b)\n",
    "popcnt = np.sum(xor)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "eps = .002\n",
    "ax = plt.gca()\n",
    "\n",
    "hash_l = .24\n",
    "hash_r = .995\n",
    "vheight = (hash_l - hash_r)/16\n",
    "\n",
    "plt.imshow(hash_a[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1., 1 - vheight + eps), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - vheight), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.imshow(hash_b[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1 - 3*vheight/2 + eps, 1 - 5*vheight/2), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - 5*vheight/2), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.imshow(xor[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1 - 3*vheight, 1 - 4*vheight), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - 4*vheight), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.plot([hash_l*.7, hash_r], [1 - 11*vheight/4, 1 - 11*vheight/4], 'k', lw=2)\n",
    "\n",
    "ax.add_patch(plt.Circle((hash_l*.8, 1 - 2*vheight), vheight/2, fc='none', lw=2))\n",
    "plt.plot((hash_l*.8, hash_l*.8), (1 - 3*vheight/2, 1 - 5*vheight/2), 'k', lw=2)\n",
    "plt.plot((hash_l*.8 - vheight/2, hash_l*.8 + vheight/2), (1 - 2*vheight, 1 - 2*vheight), 'k', lw=2)\n",
    "\n",
    "plt.text(hash_l/2, 1 - 7*vheight/2 + .003, 'POPCNT(', va='center', ha='center',\n",
    "         fontdict={'size': 28, 'family': 'monospace'})\n",
    "plt.text(hash_r + (1 - hash_r)/2., 1 - 7*vheight/2 + .003, ')$\\;$=$\\;${}'.format(popcnt),\n",
    "         va='center', ha='left', fontdict={'size': 28, 'family': 'monospace'})\n",
    "\n",
    "plt.axis([0, 1, 1 - 4*vheight + .01, 1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('5-popcnt.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many false positives/negatives do we get from thresholding the alignment scores at .5?\n",
    "with open(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/alignment_ratings.csv')) as f:\n",
    "    reader = csv.reader(f)\n",
    "    # Cast each entry in each row to the correct type\n",
    "    ratings = [[int(alignment_id), int(rating), np.clip(2*(1 - float(score)), 0, 1), note]\n",
    "               for alignment_id, rating, score, note in reader]\n",
    "print np.sum([r[1] <= 2 and r[2] >= .5 for r in ratings])\n",
    "print np.sum([r[1] >= 3 and r[2] <= .5 for r in ratings])\n",
    "print np.sum([r[1] >= 3 and r[2] >= .5 for r in ratings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import deepdish\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('/Users/craffel/Documents/projects/midi-dataset/')\n",
    "import experiment_utils\n",
    "import whoosh_search\n",
    "import feature_extraction\n",
    "RESULTS_PATH = '/Users/craffel/Documents/projects/midi-dataset/results/'\n",
    "import dhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def paa(sequence, window):\n",
    "    \"\"\"\n",
    "    Compute ``Piecewise Aggregate Approximation'' of a sequence, which simply\n",
    "    computes the local mean of the sequence over non-overlapping windows\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : np.ndarray\n",
    "        A sequence; will be aggregated over its first dimension.\n",
    "    window : int\n",
    "        Size of windows over which to compute the mean\n",
    "    Returns\n",
    "    -------\n",
    "    aggregated_sequence : np.ndarray\n",
    "        Aggregated sequence, the first dimension will be 1/window of its\n",
    "        original size\n",
    "    \"\"\"\n",
    "    # Truncate sequence to rounded-down nearest divisor\n",
    "    sequence = sequence[:window*int(sequence.shape[0]/window)]\n",
    "    # Reshape sequence to be of shape\n",
    "    # (original_shape[0]/window, window, original trailing dimensions...)\n",
    "    sequence = sequence.reshape(\n",
    "            sequence.shape[0]/window, window, sequence.shape[-1])\n",
    "    # Compute mean over the window dimension\n",
    "    return sequence.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all parameter optimization trials\n",
    "trial_files = glob.glob(os.path.join(\n",
    "    RESULTS_PATH, 'dhs_parameter_trials', '*.h5'))\n",
    "trials = [deepdish.io.load(f) for f in trial_files]\n",
    "# Get the hyperparameters for the trial with the lowest objective value\n",
    "best_trial = sorted(trials, key=lambda t: t['best_objective'])[0]\n",
    "hyperparameters = best_trial['hyperparameters']\n",
    "# Load in the pre-trained parameters for the best performing models\n",
    "network_params = deepdish.io.load(\n",
    "    os.path.join(RESULTS_PATH, 'dhs_model', 'best_model.h5'))\n",
    "compute_output = {}\n",
    "training_mean = {}\n",
    "# Build networks and output-computing functions\n",
    "for dataset, network in zip(['clean_midi', 'msd'], ['X', 'Y']):\n",
    "    # Construct the network according to best-trial hyperparameters\n",
    "    if hyperparameters['network'] == 'dhs_big_filter':\n",
    "        build_network = experiment_utils.build_dhs_net_big_filter\n",
    "    elif hyperparameters['network'] == 'dhs_small_filters':\n",
    "        build_network = experiment_utils.build_dhs_net_small_filters\n",
    "    layers = build_network(\n",
    "        (None, 1, None, feature_extraction.N_NOTES),\n",
    "        # We will supply placeholders here but load in the values below\n",
    "        np.zeros((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        np.ones((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        hyperparameters['downsample_frequency'])\n",
    "    # Load in network parameter values\n",
    "    lasagne.layers.set_all_param_values(\n",
    "        layers[-1], network_params[network])\n",
    "    # Retrieve the training set mean from the bias layer created by the standardization layer\n",
    "    training_mean[network] = -lasagne.layers.get_all_layers(layers[-1])[1].b.get_value()\n",
    "    # Compile function for computing the output of the network\n",
    "    compute_output[network] = theano.function(\n",
    "        [layers[0].input_var],\n",
    "        lasagne.layers.get_output(layers[-1], deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in all parameter optimization trials\n",
    "trial_files = glob.glob(os.path.join(\n",
    "    RESULTS_PATH, 'dhs_piano_parameter_trials', '*.h5'))\n",
    "trials = [deepdish.io.load(f) for f in trial_files]\n",
    "# Get the hyperparameters for the trial with the lowest objective value\n",
    "best_trial = sorted(trials, key=lambda t: t['best_objective'])[0]\n",
    "hyperparameters = best_trial['hyperparameters']\n",
    "# Load in the pre-trained parameters for the best performing models\n",
    "network_params = deepdish.io.load(\n",
    "    os.path.join(RESULTS_PATH, 'dhs_piano_model', 'best_model.h5'))\n",
    "compute_output_piano = {}\n",
    "# Build networks and output-computing functions\n",
    "for dataset, network in zip(['clean_midi', 'msd'], ['X', 'Y']):\n",
    "    # Construct the network according to best-trial hyperparameters\n",
    "    if hyperparameters['network'] == 'dhs_big_filter':\n",
    "        build_network = experiment_utils.build_dhs_net_big_filter\n",
    "    elif hyperparameters['network'] == 'dhs_small_filters':\n",
    "        build_network = experiment_utils.build_dhs_net_small_filters\n",
    "    layers = build_network(\n",
    "        (None, 1, None, feature_extraction.N_NOTES),\n",
    "        # We will supply placeholders here but load in the values below\n",
    "        np.zeros((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        np.ones((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        hyperparameters['downsample_frequency'])\n",
    "    # Load in network parameter values\n",
    "    lasagne.layers.set_all_param_values(\n",
    "        layers[-1], network_params[network])\n",
    "    # Compile function for computing the output of the network\n",
    "    compute_output_piano[network] = theano.function(\n",
    "        [layers[0].input_var],\n",
    "        lasagne.layers.get_output(layers[-1], deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_examples = 100\n",
    "\n",
    "validation_path = os.path.join(RESULTS_PATH, 'training_dataset', 'validate', 'h5')\n",
    "validation_raw = [deepdish.io.load(f) for f in glob.glob(os.path.join(validation_path, '*.h5'))[:n_examples]]\n",
    "validation_raw = [dict((k, d[k][0]) for k in ['X', 'Y']) for d in validation_raw]\n",
    "\n",
    "validation_path = os.path.join(RESULTS_PATH, 'training_dataset_piano_roll', 'validate', 'h5')\n",
    "validation_piano = [deepdish.io.load(f) for f in glob.glob(os.path.join(validation_path, '*.h5'))[:n_examples]]\n",
    "validation_piano = [dict((k, d[k][0]) for k in ['X', 'Y']) for d in validation_piano]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_out = [dict((k, compute_output[k](d[k].reshape(1, 1, *d[k].shape))) for k in ['X', 'Y'])\n",
    "                  for d in validation_raw]\n",
    "validation_out_piano = [dict((k, compute_output_piano[k](d[k].reshape(1, 1, *d[k].shape))) for k in ['X', 'Y'])\n",
    "                        for d in validation_piano]\n",
    "validation_paa = [dict((k, paa(d[k], 8)) for k in ['X', 'Y']) for d in validation_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_hash = [dict((k, 1*(d[k] > 0)) for k in ['X', 'Y']) for d in validation_out]\n",
    "validation_hash_piano = [dict((k, 1*(d[k] > 0)) for k in ['X', 'Y']) for d in validation_out_piano]\n",
    "validation_tpaa = [dict((k, 1*(d[k] > training_mean[k])) for k in ['X', 'Y']) for d in validation_paa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "representations = [validation_raw, validation_hash, \n",
    "                   validation_piano, validation_hash_piano,\n",
    "                   validation_out, validation_tpaa]\n",
    "fig = plt.figure(figsize=(FIGSIZE[0], 1.5*FIGSIZE[1]))\n",
    "for n, rep in enumerate(representations):\n",
    "    all_X = np.concatenate([d['X'] for d in rep])\n",
    "    all_Y = np.concatenate([d['Y'] for d in rep])\n",
    "    all_Y_n = all_Y[dhs.random_derangement(all_Y.shape[0])]\n",
    "    p_distances = np.sum((all_X - all_Y)**2, axis=1)\n",
    "    n_distances = np.sum((all_X - all_Y_n)**2, axis=1)\n",
    "    if rep is validation_hash or rep is validation_hash_piano or rep is validation_tpaa:\n",
    "        min_dist = 0\n",
    "        max_dist = 32\n",
    "    elif rep is validation_piano:\n",
    "        min_dist = 1.9\n",
    "        max_dist = max(max(p_distances), max(n_distances))\n",
    "    else:\n",
    "        min_dist = 0\n",
    "        max_dist = max(np.percentile(p_distances, 99), np.percentile(n_distances, 99))\n",
    "    if n % 2:\n",
    "        colors = [BLUE, GREEN]\n",
    "    else:\n",
    "        colors = [RED, ORANGE]\n",
    "    plt.subplot(3, 2, n + 1)\n",
    "    plt.hist(p_distances, 32, range=[min_dist, max_dist], fc=colors[0], alpha=.7,\n",
    "             weights=np.ones(p_distances.shape[0])/p_distances.shape[0])\n",
    "    plt.hist(n_distances, 32, range=[min_dist, max_dist], fc=colors[1], alpha=.7,\n",
    "             weights=np.ones(n_distances.shape[0])/n_distances.shape[0])\n",
    "    plt.xlim(min_dist, max_dist)\n",
    "    pos, labels = plt.yticks()\n",
    "    if np.diff(pos)[0] < .02:\n",
    "        plt.yticks(np.linspace(0, .1, 6, endpoint=True))\n",
    "\n",
    "fig.text(0.5, 0.085, 'Distance', ha='center', va='center')\n",
    "fig.text(0.065, 0.5, 'Proportion', ha='center', va='center', rotation='vertical')\n",
    "        \n",
    "#plt.tight_layout()\n",
    "plt.savefig('5-distributions.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get pre-computed CQT for matching MIDI and MSD\n",
    "midi_gram = deepdish.io.load('data/5-midi-features.h5')['gram']\n",
    "audio_gram = deepdish.io.load('data/5-msd-features.h5')['gram']\n",
    "# Construct PrettyMIDI object to get piano roll\n",
    "pm = pretty_midi.PrettyMIDI('data/5-midi.mid')\n",
    "# Create list of frames whose spacing matches CQT spacing\n",
    "max_frame = int(pm.get_end_time() *\n",
    "                feature_extraction.MIDI_FS /\n",
    "                feature_extraction.MIDI_HOP)\n",
    "midi_frame_times = librosa.frames_to_time(\n",
    "    np.arange(max_frame), sr=feature_extraction.MIDI_FS,\n",
    "    hop_length=feature_extraction.MIDI_HOP)\n",
    "# Retrieve piano roll\n",
    "piano_roll = pm.get_piano_roll(times=midi_frame_times)\n",
    "# Only utilize the same notes which are used in the CQT\n",
    "piano_roll = piano_roll[\n",
    "    feature_extraction.NOTE_START:\n",
    "    (feature_extraction.NOTE_START +\n",
    "     feature_extraction.N_NOTES)]\n",
    "piano_roll = piano_roll.T\n",
    "piano_roll = librosa.util.normalize(piano_roll, norm=2, axis=1)\n",
    "# Use float32 for Theano\n",
    "piano_roll = piano_roll.astype(np.float32)\n",
    "\n",
    "midi_out = compute_output['X'](midi_gram.reshape(1, 1, *midi_gram.shape))\n",
    "msd_out = compute_output['Y'](audio_gram.reshape(1, 1, *audio_gram.shape))\n",
    "midi_hash_vectors = midi_out > 0\n",
    "msd_hash_vectors = msd_out > 0\n",
    "\n",
    "midi_tpaa = paa(midi_gram, 8) > training_mean['X']\n",
    "msd_tpaa = paa(audio_gram, 8) > training_mean['Y']\n",
    "\n",
    "midi_piano_hash_vectors = compute_output_piano['X'](piano_roll.reshape(1, 1, *piano_roll.shape)) > 0\n",
    "msd_piano_hash_vectors = compute_output_piano['Y'](audio_gram.reshape(1, 1, *audio_gram.shape)) > 0\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig = plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    gs1 = matplotlib.gridspec.GridSpec(\n",
    "        2, 2, width_ratios=[audio_gram.shape[0],\n",
    "                            midi_gram.shape[0]],\n",
    "        height_ratios=[48, 32])\n",
    "    gs1.update(top=1., bottom=0., wspace=.04, hspace=.35)\n",
    "\n",
    "    cqt_spacing = 400\n",
    "\n",
    "    ax = plt.subplot(gs1[0])\n",
    "    ax.imshow(audio_gram.T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(audio_gram, 1),\n",
    "              vmax=np.percentile(audio_gram, 99))\n",
    "    ax.set_xticks(np.arange(0, audio_gram.shape[0], cqt_spacing))\n",
    "    ax.set_yticks(np.arange(0, audio_gram.shape[1], 12))\n",
    "    ax.set_yticklabels(['C{}'.format(n) for n in [3, 4, 5, 6]])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs1[1])\n",
    "    ax.imshow(midi_gram.T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(midi_gram, 1),\n",
    "              vmax=np.percentile(midi_gram, 99))\n",
    "    ax.set_xticks(np.arange(0, midi_gram.shape[0], cqt_spacing))\n",
    "    ax.set_yticks(np.arange(0, audio_gram.shape[1], 12))\n",
    "    ax.set_yticklabels(['' for _ in [3, 4, 5, 6]])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    hash_spacing = cqt_spacing/8\n",
    "\n",
    "    ax = plt.subplot(gs1[2])\n",
    "    ax.imshow(msd_hash_vectors.T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot)\n",
    "    ax.set_xticks(np.arange(0, msd_hash_vectors.shape[0], hash_spacing))\n",
    "    ax.set_yticks(np.arange(0, msd_hash_vectors.shape[1], 8))\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs1[3])\n",
    "    ax.imshow(midi_hash_vectors.T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot)\n",
    "    ax.set_xticks(np.arange(0, midi_hash_vectors.shape[0], hash_spacing))\n",
    "    ax.set_yticks(np.arange(0, midi_hash_vectors.shape[1], 8))\n",
    "    ax.set_yticklabels(['' for _ in np.arange(0, msd_hash_vectors.shape[1], 4)])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    fig.text(0.5, -0.15, 'Sequence Index', ha='center', va='center')\n",
    "    fig.text(0.085, 0.5, 'Feature', ha='center', va='center', rotation='vertical')\n",
    "    plt.savefig('5-cqts_and_dhs.pdf',  bbox_inches='tight', pad_inches=0.1)    \n",
    "\n",
    "    \n",
    "    \n",
    "    cqt_spacing_x = 400\n",
    "    cqt_spacing_y = 200\n",
    "    hash_spacing_x = cqt_spacing_x/8\n",
    "    hash_spacing_y = cqt_spacing_y/8\n",
    "\n",
    "    fig = plt.figure(figsize=(FIGSIZE[0], 8))\n",
    "    ax = plt.subplot(4, 1, 1)\n",
    "    dist_mat = (1 - np.dot(midi_gram, audio_gram.T))\n",
    "    ax.imshow(dist_mat.T,\n",
    "              interpolation='nearest', cmap=plt.cm.gray,\n",
    "              vmin=np.percentile(dist_mat, 1),\n",
    "              vmax=np.percentile(dist_mat, 99.9))\n",
    "    tight = ax.axis()\n",
    "    p, q, _ = djitw.dtw(dist_mat, .96, np.median(dist_mat), inplace=False)\n",
    "    ax.plot(p, q, 'w--', lw=3)\n",
    "    ax.axis(tight)\n",
    "    ax.set_xticks(np.arange(0, midi_gram.shape[0], cqt_spacing_x))\n",
    "    ax.set_yticks(np.arange(0, audio_gram.shape[0], cqt_spacing_y))\n",
    "\n",
    "    dist_mat = scipy.spatial.distance.cdist(midi_hash_vectors, msd_hash_vectors, 'sqeuclidean')\n",
    "    ax = plt.subplot(4, 1, 2)\n",
    "    ax.imshow(dist_mat.T, interpolation='nearest', cmap=plt.cm.gray)\n",
    "    tight = ax.axis()\n",
    "    p, q, _ = djitw.dtw(dist_mat, .9, 15, inplace=False)\n",
    "    ax.axis(tight)\n",
    "    ax.plot(p, q, 'w--', lw=3)\n",
    "    ax.set_xticks(np.arange(0, midi_hash_vectors.shape[0], hash_spacing_x))\n",
    "    ax.set_yticks(np.arange(0, msd_hash_vectors.shape[0], hash_spacing_y))\n",
    "\n",
    "    dist_mat = scipy.spatial.distance.cdist(midi_piano_hash_vectors, msd_piano_hash_vectors, 'sqeuclidean')\n",
    "    ax = plt.subplot(4, 1, 3)\n",
    "    ax.imshow(dist_mat.T, interpolation='nearest', cmap=plt.cm.gray)\n",
    "    tight = ax.axis()\n",
    "    p, q, _ = djitw.dtw(dist_mat, .9, 15, inplace=False)\n",
    "    ax.axis(tight)\n",
    "    ax.plot(p, q, 'w--', lw=3)\n",
    "    ax.set_xticks(np.arange(0, midi_piano_hash_vectors.shape[0], hash_spacing_x))\n",
    "    ax.set_yticks(np.arange(0, msd_piano_hash_vectors.shape[0], hash_spacing_y))\n",
    "\n",
    "    dist_mat = scipy.spatial.distance.cdist(midi_tpaa, msd_tpaa, 'sqeuclidean')\n",
    "    ax = plt.subplot(4, 1, 4)\n",
    "    ax.imshow(dist_mat.T, interpolation='nearest', cmap=plt.cm.gray)\n",
    "    tight = ax.axis()\n",
    "    p, q, _ = djitw.dtw(dist_mat, .9, 15, inplace=False)\n",
    "    ax.axis(tight)\n",
    "    ax.plot(p, q, 'w--', lw=3)\n",
    "    ax.set_xticks(np.arange(0, midi_tpaa.shape[0], hash_spacing_x))\n",
    "    ax.set_yticks(np.arange(0, msd_tpaa.shape[0], hash_spacing_y))\n",
    "    \n",
    "    fig.text(0.5, 0.085, 'MIDI Sequence Index', ha='center', va='center')\n",
    "    fig.text(0.085, 0.5, 'Audio Sequence Index', ha='center', va='center', rotation='vertical')\n",
    "    plt.savefig('5-distance_matrices.pdf',  bbox_inches='tight', pad_inches=0.1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prop_below(results):\n",
    "    ranks = [min(r['msd_match_ranks']) for r in results]\n",
    "    lt = np.less.outer(ranks, np.arange(1000000))\n",
    "    return np.mean(lt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_curves = {}\n",
    "for rep in ['dhs', 'dhs_piano', 'tpaa']:\n",
    "    results = deepdish.io.load(os.path.join(RESULTS_PATH, '{}_match_results/test_results.h5'.format(rep)))\n",
    "    rank_curves[rep] = prop_below(results)\n",
    "    ranks = [min(r['msd_match_ranks']) for r in results]\n",
    "    print '{} MRR: {}, rank 1: {}, rank for < 95%: {}'.format(\n",
    "        rep,\n",
    "        np.mean([1./(r + 1) for r in ranks]),\n",
    "        np.mean(np.less(ranks, 1)),\n",
    "        np.argmax(rank_curves[rep] > .95) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "for rep, color in zip(['dhs', 'dhs_piano', 'tpaa'], [BLUE, GREEN, RED]):\n",
    "    plt.semilogx(100*rank_curves[rep], color, lw=2)\n",
    "plt.ylim(0, 102)\n",
    "plt.ylabel('Percentage below')\n",
    "plt.xlabel('Rank')\n",
    "plt.text(1.2, 87, 'DHS, CQT', {'color': BLUE, 'weight': 'bold', 'size': 16})\n",
    "plt.text(10, 76, 'DHS, Piano roll', {'color': GREEN, 'weight': 'bold', 'size': 16})\n",
    "plt.text(10, 76, 'DHS, Piano roll', {'color': 'k', 'weight': 'bold', 'size': 16}, alpha=.1)\n",
    "plt.text(100, 53, 'TPAA', {'color': RED, 'weight': 'bold', 'size': 16})\n",
    "plt.savefig('5-ranks.pdf',  bbox_inches='tight', pad_inches=0.1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canvas_height = .7\n",
    "\n",
    "plt.figure(figsize=(FIGSIZE[0], FIGSIZE[0]*canvas_height))\n",
    "\n",
    "eps = 1e-3\n",
    "\n",
    "ax = plt.gca()\n",
    "axis = ax.axis((0, 1, 0, canvas_height))\n",
    "\n",
    "# Grid\n",
    "if 0:\n",
    "    for n in np.linspace(0, 1, 21):\n",
    "        plt.plot([0, 1], [n, n], 'k:')\n",
    "        plt.plot([n, n], [0, 1], 'k:')\n",
    "        ax.annotate(s=str(n),\n",
    "                xy=(0., n), ha='center', va='center', family='sans-serif')\n",
    "        ax.annotate(s=str(n),\n",
    "                xy=(n, 1.), ha='center', va='center', family='sans-serif')\n",
    "\n",
    "\n",
    "# h_t boxes\n",
    "h_t_width = .1\n",
    "h_t_height = .3\n",
    "sum_bottom = .53\n",
    "for m, n in enumerate([0, 1, 2, 4]):\n",
    "    h_box = matplotlib.patches.Rectangle(\n",
    "        (.05 + n/5., eps), h_t_width, h_t_height,\n",
    "        facecolor=GREEN, edgecolor='k', lw=2)\n",
    "    ax.add_patch(h_box)\n",
    "\n",
    "    plt.plot([.05 + n/5. + h_t_width/2., .5],\n",
    "             [h_t_height, sum_bottom], '#cccccc', lw=2, zorder=-2)\n",
    "\n",
    "    circle_center_x = (.05 + n/5. + h_t_width/2. + .5)/2.\n",
    "    circle_center_y = (h_t_height + sum_bottom)/2.\n",
    "    circle_radius = .02\n",
    "    circle = plt.Circle((circle_center_x, circle_center_y), circle_radius,\n",
    "                        color=ORANGE, ec='k', zorder=4)\n",
    "    ax.add_artist(circle)\n",
    "    circle_offset = .8*(np.sqrt(2)/2)*circle_radius\n",
    "    plt.plot([circle_center_x - circle_offset, circle_center_x + circle_offset],\n",
    "             [circle_center_y - circle_offset, circle_center_y + circle_offset],\n",
    "             'k', lw=1.5, zorder=5)\n",
    "    plt.plot([circle_center_x - circle_offset, circle_center_x + circle_offset],\n",
    "             [circle_center_y + circle_offset, circle_center_y - circle_offset],\n",
    "             'k', lw=1.5, zorder=5)\n",
    "    \n",
    "    spline_y = [.36, .38, .39*.1 + .9*circle_center_x, circle_center_x][::-1]\n",
    "    spline_x = [.55, .54 + .01*n/6., circle_center_y + circle_radius*2,\n",
    "                circle_center_y + circle_radius][::-1]\n",
    "    interpolated_x = np.linspace(spline_x[0], spline_x[-1], 100)\n",
    "    interpolated_y = scipy.interpolate.spline(spline_x, spline_y, interpolated_x, 3)\n",
    "    plt.plot(interpolated_y, interpolated_x, 'k', ls='dashed')\n",
    "\n",
    "    spline_y = [.06, .05 - .03*m/4., .05 + .2*n/5., .05 + n/5. + h_t_width/2][::-1]\n",
    "    spline_x = [.55, .5 + .02*m/4., .4, h_t_height][::-1]\n",
    "    interpolated_x = np.linspace(spline_x[0], spline_x[-1], 100)\n",
    "    interpolated_y = scipy.interpolate.spline(spline_x, spline_y, interpolated_x, 3)\n",
    "    plt.plot(interpolated_y, interpolated_x, 'k', ls='dashed')\n",
    "    \n",
    "    ax.text(circle_center_x + .015*(n == 0), circle_center_y + circle_offset,\n",
    "            '$\\\\alpha[{}]$'.format(n + 1 if n < 3 else 'T\\,'),\n",
    "            horizontalalignment='left',\n",
    "            verticalalignment='bottom', fontsize=22, zorder=5)\n",
    "    \n",
    "    ax.text(.05 + n/5. + h_t_width/2, h_t_height/2, '$h[{}]$'.format(n + 1 if n < 3 else 'T\\,'),\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center', fontsize=26, zorder=5)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Dots\n",
    "dot_spacing = .05\n",
    "for offset in [-1, 0, 1]:\n",
    "    circle = plt.Circle((.7 + offset*dot_spacing, h_t_height/2),\n",
    "                        .007, color='k', ec='k', zorder=4)\n",
    "    ax.add_artist(circle)\n",
    "\n",
    "draw_neural_net(ax, .1, .35, .4, .7, [3, 5, 1])\n",
    "draw_brace(ax, .06, .08, .475, .625, 1000., 0, 0)\n",
    "\n",
    "ax.text(.1, .7, '$a(h[t])$',\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='top', fontsize=24, zorder=5)\n",
    "    \n",
    "# + circle\n",
    "circle_center_x = .5\n",
    "circle_center_y = .55\n",
    "circle_radius = .02\n",
    "circle = plt.Circle((circle_center_x, circle_center_y), circle_radius,\n",
    "                     color=ORANGE, ec='k', zorder=4)\n",
    "ax.add_artist(circle)\n",
    "circle_offset = .8*circle_radius\n",
    "plt.plot([circle_center_x, circle_center_x],\n",
    "         [circle_center_y - circle_offset, circle_center_y + circle_offset],\n",
    "         'k', lw=1.5, zorder=5)\n",
    "plt.plot([circle_center_x - circle_offset, circle_center_x + circle_offset],\n",
    "         [circle_center_y, circle_center_y],\n",
    "         'k', lw=1.5, zorder=5)\n",
    "\n",
    "c_box = matplotlib.patches.Rectangle(\n",
    "    (.85 - h_t_width/2., .55 - h_t_height/2. - eps), h_t_width, h_t_height,\n",
    "    facecolor=BLUE, edgecolor='k', lw=2, alpha=.7)\n",
    "ax.add_patch(c_box)\n",
    "ax.text(.85, .55, '$c$',\n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center', fontsize=30, zorder=5)\n",
    "ax.arrow(circle_center_x + circle_radius + .005, .55,\n",
    "         .85 - h_t_width/2 - .55 - .01, 0.,\n",
    "         head_width=0.025, head_length=0.025, fc='k', ec='k')\n",
    "\n",
    "ax.axis(axis)\n",
    "ax.get_xaxis().set_visible(False)\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.savefig('6-attention_schematic.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "import theano\n",
    "import deepdish\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append('/Users/craffel/Documents/projects/midi-dataset/')\n",
    "import experiment_utils\n",
    "import whoosh_search\n",
    "import feature_extraction\n",
    "RESULTS_PATH = '/Users/craffel/Documents/projects/midi-dataset/results/'\n",
    "import pse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_statistics(gram):\n",
    "    '''\n",
    "    Computes the mean and standard deviation of feature dimensions in a\n",
    "    provided feature vector sequence.\n",
    "    Parameters\n",
    "    ----------\n",
    "    gram : np.ndarray\n",
    "        Constant-Q spectrogram, shape=(n_frames, n_frequency_bins)\n",
    "    Returns\n",
    "    -------\n",
    "    statistics : np.ndarray\n",
    "        Stacked mean and standard deviation.\n",
    "    '''\n",
    "    # Compute and stack statistics, adding a \"n_samples\" dimension in front\n",
    "    return np.concatenate((gram.mean(axis=0), gram.std(axis=0)))[np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all parameter optimization trials\n",
    "trial_files = glob.glob(os.path.join(\n",
    "    RESULTS_PATH, 'pse_parameter_trials', '*.h5'))\n",
    "trials = [deepdish.io.load(f) for f in trial_files]\n",
    "# Get the hyperparameters for the trial with the lowest objective value\n",
    "best_trial = sorted(trials, key=lambda t: t['best_objective'])[0]\n",
    "hyperparameters = best_trial['hyperparameters']\n",
    "# Load in the pre-trained parameters for the best performing models\n",
    "network_params = deepdish.io.load(\n",
    "    os.path.join(RESULTS_PATH, 'pse_model', 'best_model.h5'))\n",
    "compute_output = {}\n",
    "layers = {}\n",
    "# Build networks and output-computing functions\n",
    "for dataset, network in zip(['clean_midi', 'msd'], ['X', 'Y']):\n",
    "    # Construct the network according to best-trial hyperparameters\n",
    "    if hyperparameters['network'] == 'pse_big_filter':\n",
    "        build_network = experiment_utils.build_pse_net_big_filter\n",
    "    elif hyperparameters['network'] == 'pse_small_filters':\n",
    "        build_network = experiment_utils.build_pse_net_small_filters\n",
    "    # PSE trials do not have this hyperparameter by default, so as in\n",
    "    # experiment_utils.run_trial, we must set the default value\n",
    "    hyperparameters['downsample_frequency'] = hyperparameters.get(\n",
    "        'downsample_frequency', True)        \n",
    "    layers[network] = build_network(\n",
    "        (None, 1, None, feature_extraction.N_NOTES),\n",
    "        # We will supply placeholders here but load in the values below\n",
    "        np.zeros((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        np.ones((1, feature_extraction.N_NOTES), theano.config.floatX),\n",
    "        hyperparameters['downsample_frequency'],\n",
    "        hyperparameters['n_attention'], hyperparameters['n_conv'])\n",
    "    # Load in network parameter values\n",
    "    lasagne.layers.set_all_param_values(\n",
    "        layers[network][-1], network_params[network])\n",
    "    # Compile function for computing the output of the network\n",
    "    compute_output[network] = theano.function(\n",
    "        [layers[network][0].input_var],\n",
    "        lasagne.layers.get_output(layers[network][-1], deterministic=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_path = os.path.join(RESULTS_PATH, 'training_dataset_unaligned', 'validate', 'h5')\n",
    "validation_raw = [deepdish.io.load(f) for f in glob.glob(os.path.join(validation_path, '*.h5'))]\n",
    "validation_raw = [dict((k, d[k][0]) for k in ['X', 'Y']) for d in validation_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_stats = [dict((k, compute_statistics(d[k])) for k in ['X', 'Y'])\n",
    "                    for d in validation_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validation_out = [dict((k, compute_output[k](d[k].reshape(1, 1, *d[k].shape))) for k in ['X', 'Y'])\n",
    "                  for d in validation_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], .4*FIGSIZE[0]/.7))\n",
    "with sns.axes_style('white'):\n",
    "    ax = plt.gca()\n",
    "    eps = .001\n",
    "    ax.add_patch(matplotlib.patches.Rectangle((.3, .85), .4 + eps, .15, fc='None'))\n",
    "    ax.imshow(validation_raw[100]['Y'].T,\n",
    "              interpolation='nearest', aspect='auto', cmap=plt.cm.hot,\n",
    "              origin='lower', extent=(.3, .7, .85, 1.),\n",
    "              vmin=np.percentile(validation_raw[100]['Y'], 1),\n",
    "              vmax=np.percentile(validation_raw[100]['Y'], 99))\n",
    "\n",
    "    for n in xrange(32):\n",
    "        ax.add_patch(matplotlib.patches.Rectangle((.2 + .5*(n/31.) - (.7 - .3)/8, .7 - .03*(n/31.)),\n",
    "                                                  (.7 - .3)/2, (.15 - 0.)/2, fc=ORANGE))\n",
    "    ax.add_patch(matplotlib.patches.Polygon([[.3, .85],\n",
    "                                             [.2 - (.7 - .3)/8, .7 + (.15 - 0.)/2],\n",
    "                                             [.7 - (.7 - .3)/8 + (.7 - .3)/2 - eps, .74],\n",
    "                                             [.7 - (.7 - .3)/8 + (.7 - .3)/2 - eps, .7 - .03 + (.15 - 0.)/2],\n",
    "                                             [.7, .85]], ec='none', fc=BLUE, zorder=-1, alpha=.8))\n",
    "    ax.annotate(s=u'33 convolution, 22 max-pool',\n",
    "                xy=(.49, .81), fontsize=16, ha='center', va='center', family='sans-serif')\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Polygon([[.2 - (.7 - .3)/8, .7],\n",
    "                                             [.35 - .01, .611],\n",
    "                                             [.35 - .005, .58],\n",
    "                                             [.35 + .005, .58],\n",
    "                                             [.35 + .01, .611],\n",
    "                                             [.7 - (.7 - .3)/8 + (.7 - .3)/2, .7 - .03],\n",
    "                                             [.2 - (.7 - .3)/8, .72]],\n",
    "                                            ec='none', fc='#CCCCCC', zorder=-1, alpha=.8))\n",
    "    ax.annotate(s=u'Feedforward Attention',\n",
    "                xy=(.28, .655), fontsize=16, ha='left', va='center', family='sans-serif')\n",
    "    \n",
    "    ax.add_patch(matplotlib.patches.Rectangle((.35 - .005, .43), .01, .15, fc=ORANGE, ec='k'))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Polygon([[.35 + .005, .43],\n",
    "                                             [.45 - .005, .40],\n",
    "                                             [.45 - .005, .61],\n",
    "                                             [.35 + .005, .58]],\n",
    "                                            ec='none', fc=GREEN, zorder=-1, alpha=.8))\n",
    "\n",
    "    ax.annotate(s=u'Dense\\nReLU',\n",
    "                xy=(.4, .505), fontsize=16, ha='center', va='center', family='sans-serif', rotation=90)\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Rectangle((.45 - .005, .4), .01, .21, fc=ORANGE, ec='k'))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Polygon([[.45 + .005, .4],\n",
    "                                             [.55 - .005, .4],\n",
    "                                             [.55 - .005, .61],\n",
    "                                             [.45 + .005, .61]],\n",
    "                                            ec='none', fc=GREEN, zorder=-1, alpha=.8))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Rectangle((.55 - .005, .4), .01, .21, fc=ORANGE, ec='k'))\n",
    "\n",
    "    ax.annotate(s=u'Dense\\nReLU',\n",
    "                xy=(.5, .505), fontsize=16, ha='center', va='center', family='sans-serif', rotation=90)\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.Polygon([[.55 + .005, .4],\n",
    "                                             [.65 - .005, .455],\n",
    "                                             [.65 - .005, .555],\n",
    "                                             [.55 + .005, .61]],\n",
    "                                            ec='none', fc=GREEN, zorder=-1, alpha=.8))\n",
    "    ax.annotate(s=u'Dense\\ntanh',\n",
    "                xy=(.6, .505), fontsize=16, ha='center', va='center', family='sans-serif', rotation=90)\n",
    "\n",
    "    ax.imshow(np.array([np.random.random_sample(24)*.5]).T, cmap=plt.cm.hot,\n",
    "              extent=(.65 - .005, .65 + .005, .455, .555), interpolation='nearest')\n",
    "    ax.add_patch(matplotlib.patches.Rectangle((.65 - .005, .455), .01 + eps, .1, fc='None'))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.plot([0, 1], [0, 1], alpha=0.)\n",
    "    plt.xlim([0.15 - eps, 0.85 + .005])\n",
    "    plt.ylim([.4 - eps, 1 + eps])\n",
    "    if False:\n",
    "        for n in np.linspace(0, 1, 21):\n",
    "            plt.plot([0, 1], [n, n], 'k:')\n",
    "            plt.plot([n, n], [0, 1], 'k:')\n",
    "            ax.annotate(s=str(n),\n",
    "                        xy=(0., n), ha='center', va='center', family='sans-serif')\n",
    "            ax.annotate(s=str(n),\n",
    "                        xy=(n, 1.), ha='center', va='center', family='sans-serif')\n",
    "    plt.savefig('6-model_schematic.pdf', transparent=True, bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_raw_0 = validation_raw[229]\n",
    "validation_raw_1 = validation_raw[339]\n",
    "\n",
    "X_embed_mean = np.mean(np.concatenate([o['X'] for o in validation_out]), axis=0)\n",
    "Y_embed_mean = np.mean(np.concatenate([o['Y'] for o in validation_out]), axis=0)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    fig = plt.figure(figsize=(FIGSIZE[0], 3))\n",
    "    gs1 = matplotlib.gridspec.GridSpec(\n",
    "        2, 2, width_ratios=[validation_raw_0['X'].shape[0],\n",
    "                            validation_raw_0['Y'].shape[0]])\n",
    "    gs1.update(left=.04, right=.97, top=1., bottom=.37, wspace=.02, hspace=.1)\n",
    "\n",
    "    cqt_spacing = 300\n",
    "\n",
    "    ax = plt.subplot(gs1[0])\n",
    "    ax.imshow(validation_raw_0['X'].T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(validation_raw_0['X'], 1),\n",
    "              vmax=np.percentile(validation_raw_0['X'], 99))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks(np.arange(0, validation_raw_0['X'].shape[1], 12))\n",
    "    ax.set_yticklabels(['C{}'.format(n) for n in [3, 4, 5, 6]])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs1[1])\n",
    "    ax.imshow(validation_raw_0['Y'].T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(validation_raw_0['Y'], 1),\n",
    "              vmax=np.percentile(validation_raw_0['Y'], 99))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    gs3 = matplotlib.gridspec.GridSpec(\n",
    "        1, 2, width_ratios=[validation_raw_0['X'].shape[0],\n",
    "                            validation_raw_0['Y'].shape[0]])\n",
    "    gs3.update(top=.46, bottom=.11, wspace=.02, hspace=.5)\n",
    "\n",
    "    cqt_spacing = 600\n",
    "\n",
    "    ax = plt.subplot(gs1[2])\n",
    "    ax.imshow(validation_raw_1['X'].T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(validation_raw_1['X'], 1),\n",
    "              vmax=np.percentile(validation_raw_1['X'], 99))\n",
    "    ax.set_xticks(np.arange(0, validation_raw_1['X'].shape[0], cqt_spacing))\n",
    "    ax.set_yticks(np.arange(0, validation_raw_0['X'].shape[1], 12))\n",
    "    ax.set_yticklabels(['C{}'.format(n) for n in [3, 4, 5, 6]])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs1[3])\n",
    "    ax.imshow(validation_raw_1['Y'].T, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=np.percentile(validation_raw_1['Y'], 1),\n",
    "              vmax=np.percentile(validation_raw_1['Y'], 99))\n",
    "    ax.set_xticks(np.arange(0, validation_raw_0['Y'].shape[0], cqt_spacing))\n",
    "    ax.set_yticks([])\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    fig.text(0.5, 0.27, 'Frame Index', ha='center', va='center')\n",
    "    fig.text(0.0, 0.68, 'Frequency', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "    embed_spacing = 16\n",
    "    gs2 = matplotlib.gridspec.GridSpec(2, 1)\n",
    "    gs2.update(left=.04, right=.97, top=.22, bottom=.125, wspace=.03, hspace=.2)\n",
    "\n",
    "    X_val_embed0 = validation_out[229]['X'] - X_embed_mean\n",
    "    Y_val_embed0 = validation_out[229]['Y'] - Y_embed_mean\n",
    "    X_val_embed1 = validation_out[339]['X'] - X_embed_mean\n",
    "    Y_val_embed1 = validation_out[339]['Y'] - Y_embed_mean\n",
    "    print 'Pairwise distances:'\n",
    "    print scipy.spatial.distance.cdist(\n",
    "        np.concatenate([X_val_embed0, X_val_embed1]),\n",
    "        np.concatenate([Y_val_embed0, Y_val_embed1]), 'sqeuclidean')\n",
    "\n",
    "    vmin = min([np.percentile(x, 2) for x in [X_val_embed0, X_val_embed1, Y_val_embed0, Y_val_embed1]])\n",
    "    vmax = max([np.percentile(x, 98) for x in [X_val_embed0, X_val_embed1, Y_val_embed0, Y_val_embed1]])\n",
    "\n",
    "    ax = plt.subplot(gs2[0])\n",
    "    ax.imshow(X_val_embed0, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs2[1])\n",
    "    ax.imshow(Y_val_embed0, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    gs3 = matplotlib.gridspec.GridSpec(2, 1)\n",
    "    gs3.update(left=.04, right=.97, top=.095, bottom=0., wspace=.03, hspace=.2)\n",
    "\n",
    "    ax = plt.subplot(gs3[0])\n",
    "    ax.imshow(X_val_embed1, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = plt.subplot(gs3[1])\n",
    "    ax.imshow(Y_val_embed1, aspect='auto', origin='lower',\n",
    "              interpolation='nearest', cmap=plt.cm.hot,\n",
    "              vmin=vmin, vmax=vmax)\n",
    "    ax.set_xticks(range(0, X_val_embed0.shape[1], embed_spacing) + [127])\n",
    "    ax.set_xticklabels([1] + range(embed_spacing, X_val_embed0.shape[1], embed_spacing) + [128])\n",
    "    ax.set_yticks([])\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "    ax = fig.add_axes([0., 0., 1., 1.], frameon=False)\n",
    "    ax.axis('off')\n",
    "    ax.add_patch(matplotlib.patches.FancyArrowPatch(\n",
    "        (0.04, 0.83),\n",
    "        (0.04, 0.18),\n",
    "        connectionstyle='arc3, rad=0.25',\n",
    "        alpha=.6, fc='k', ls='dashed',\n",
    "        mutation_scale=15,\n",
    "        arrowstyle='-|>'))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.FancyArrowPatch(\n",
    "        (0.97, 0.83),\n",
    "        (0.97, 0.13),\n",
    "        connectionstyle='arc3, rad=-0.25',\n",
    "        alpha=.6, fc='k', ls='dashed',\n",
    "        mutation_scale=15,\n",
    "        arrowstyle='-|>'))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.FancyArrowPatch(\n",
    "        (0.04, 0.49),\n",
    "        (0.04, 0.05),\n",
    "        connectionstyle='arc3, rad=0.3',\n",
    "        alpha=.6, fc='k', ls='dashed',\n",
    "        mutation_scale=15,\n",
    "        arrowstyle='-|>'))\n",
    "\n",
    "    ax.add_patch(matplotlib.patches.FancyArrowPatch(\n",
    "        (0.97, 0.49),\n",
    "        (0.97, 0.0),\n",
    "        connectionstyle='arc3, rad=-0.3',\n",
    "        alpha=.6, fc='k', ls='dashed',\n",
    "        mutation_scale=15,\n",
    "        arrowstyle='-|>'))\n",
    "\n",
    "    plt.savefig('6-embeddings.pdf', transparent=True, bbox_inches='tight', pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(FIGSIZE[0], 2*FIGSIZE[1]), )\n",
    "min_dist = .0025\n",
    "max_dist = .5\n",
    "for n, rep in enumerate([validation_out, validation_stats]):\n",
    "    all_X = np.concatenate([d['X'] for d in rep])\n",
    "    all_Y = np.concatenate([d['Y'] for d in rep])\n",
    "    shuffle = pse.random_derangement(all_Y.shape[0])\n",
    "    all_Y_n = all_Y[shuffle]\n",
    "    p_distances = np.sum((all_X - all_Y)**2, axis=1)\n",
    "    n_distances = np.sum((all_X - all_Y_n)**2, axis=1)\n",
    "    colors = [BLUE, GREEN]\n",
    "    #ax = plt.subplot(2, 1, n + 1, )\n",
    "    gs = matplotlib.gridspec.GridSpec(2, 1, hspace=0.08)\n",
    "    ax = plt.subplot(gs[n, 0])\n",
    "    ax.hist(p_distances, bins=10**np.linspace(np.log10(min_dist), np.log10(max_dist)),\n",
    "             fc=colors[0], alpha=.7, weights=np.ones(p_distances.shape[0])/p_distances.shape[0])\n",
    "    ax.hist(n_distances, bins=10**np.linspace(np.log10(min_dist), np.log10(max_dist)),\n",
    "             fc=colors[1], alpha=.7, weights=np.ones(n_distances.shape[0])/n_distances.shape[0])\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlim(.0025, .5)\n",
    "    plt.xticks([.005, .01, .025, .05, .1, .25], [.005, .01, .025, .05, .1, .25])\n",
    "    if n == 0:\n",
    "        ax.set_ylim(0, 0.1)\n",
    "    else:\n",
    "        plt.xlabel('Distance')    \n",
    "        ax.set_ylim(0, 0.105)\n",
    "    plt.ylabel('Proportion')\n",
    "        \n",
    "#fig.text(0.5, 0.085, 'Distance', ha='center', va='center')\n",
    "#fig.text(0.065, 0.5, 'Proportion', ha='center', va='center', rotation='vertical')\n",
    "        \n",
    "plt.savefig('6-distributions.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_curves = {}\n",
    "for rep in ['pse', 'stats']:\n",
    "    results = deepdish.io.load(os.path.join(RESULTS_PATH, '{}_match_results/test_results.h5'.format(rep)))\n",
    "    rank_curves[rep] = prop_below(results)\n",
    "    ranks = [min(r['msd_match_ranks']) for r in results]\n",
    "    print '{} MRR: {}, rank 1: {}, rank for < 95%: {}'.format(\n",
    "        rep,\n",
    "        np.mean([1./(r + 1) for r in ranks]),\n",
    "        np.mean(np.less(ranks, 1)),\n",
    "        np.argmax(rank_curves[rep] > .95) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "for rep, color in zip(['pse', 'stats'], [BLUE, GREEN]):\n",
    "    plt.semilogx(100*rank_curves[rep], color, lw=2)\n",
    "plt.ylim(0, 102)\n",
    "plt.ylabel('Percentage below')\n",
    "plt.xlabel('Rank')\n",
    "plt.text(4000, 75, 'PSE', {'color': BLUE, 'weight': 'bold', 'size': 16})\n",
    "plt.text(24000, 65, 'Statistics', {'color': GREEN, 'weight': 'bold', 'size': 16})\n",
    "plt.text(24000, 65, 'Statistics', {'color': 'k', 'weight': 'bold', 'size': 16}, alpha=.1)\n",
    "plt.savefig('6-ranks.pdf',  bbox_inches='tight', pad_inches=0.1)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
