{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import midi\n",
    "import matplotlib.patches\n",
    "import matplotlib\n",
    "import djitw\n",
    "import scipy.spatial\n",
    "import librosa\n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import glob\n",
    "import tabulate\n",
    "import ujson as json\n",
    "import collections\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_style({'grid.linewidth': 1.3})\n",
    "matplotlib.rc('font',**{'size':13, 'family':'Open Sans'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Testing colors\n",
    "BLUE = '#1a6396'\n",
    "GREEN = '#59dd97'\n",
    "ORANGE = '#E8B71A'\n",
    "GREY = '#DFDFDF'\n",
    "RED = '#DB3340'\n",
    "TAN = '#F7EAC8'\n",
    "FIGSIZE = (9, 6)\n",
    "FIGSIZE_FLAT = (9, 2)\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.gca().add_patch(plt.Rectangle((-1, -1), 8, 1.5, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((0, 0), 1, 1, fc=BLUE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((1, 0), 1, 1, fc=GREEN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((2, 0), 1, 1, fc=GREY, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((3, 0), 1, 1, fc=RED, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((4, 0), 1, 1, fc=ORANGE, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.gca().add_patch(plt.Rectangle((5, 0), 1, 1, fc=TAN, lw=0))\n",
    "plt.xlim([-1, 7])\n",
    "plt.ylim([-1, 2])\n",
    "#plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], FIGSIZE[1]*2))\n",
    "ax = plt.gca()\n",
    "t = np.linspace(.1, .9, 9)\n",
    "plt.vlines(t, 0, 1., linestyles='dashed', alpha=.3, zorder=-1)\n",
    "\n",
    "vc = .9\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for x, word in zip(t, words):\n",
    "    ax.text(x, vc, word, {'family': 'monospace', 'size': 12}, ha='center', va='center')\n",
    "\n",
    "vc = .7\n",
    "signal = .08*np.sin(2.4*t*np.pi) + vc\n",
    "plt.plot(t, signal, 'k.', ms=10)\n",
    "plt.vlines(t, [s if s > vc else vc for s in signal],\n",
    "           [s if s < vc else vc for s in signal], lw=1.2) \n",
    "\n",
    "vc = .5\n",
    "a, _ = librosa.load('data/1_A.wav')\n",
    "N = a.shape[0]\n",
    "for x in t:\n",
    "    frame = a[(x - .1)*N:(x + .1)*N]\n",
    "    spectrum = np.abs(np.fft.rfft(frame))\n",
    "    spectrum = spectrum[:spectrum.shape[0]/3]\n",
    "    spectrum = spectrum/3000.\n",
    "    plt.plot(x + spectrum, np.linspace(vc - .08, vc + .08, spectrum.shape[0]), 'k')\n",
    "\n",
    "axis = plt.axis()\n",
    "vc = .3\n",
    "w = .02\n",
    "h = .08\n",
    "dna_names = ['T', 'A', 'C', 'G']\n",
    "for x in t:\n",
    "    dna = np.zeros((4, 1))\n",
    "    n = np.random.randint(0, 4)\n",
    "    dna[n] = 1\n",
    "    plt.imshow(dna, interpolation='nearest', extent=(x - w, x + w, vc - h/2, vc + h), cmap=plt.cm.gray)\n",
    "    plt.plot((x - w, x - w, x + w, x + w, x - w), (vc - h/2, vc + h, vc + h, vc - h/2, vc - h/2), 'k')\n",
    "    ax.text(x, vc - h/2 - .01, dna_names[n], {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "plt.axis(axis)\n",
    "\n",
    "vc = .1\n",
    "for n, x in enumerate(t):\n",
    "    im = plt.imread('data/1_video/{}.png'.format(n + 1))\n",
    "    plt.imshow(im, interpolation='nearest', extent=(x - .03, x + .03, vc - .08, vc + .08))\n",
    "\n",
    "plt.xlim([0.05, 0.95])\n",
    "plt.ylim([0, 1])\n",
    "plt.yticks([])\n",
    "plt.axis('off')\n",
    "\n",
    "vc = 0.\n",
    "words = 'The quick brown fox jumps over the lazy dog'.split(' ')\n",
    "for n, x in enumerate(t):\n",
    "    ax.text(x, vc, '$t_{}$'.format(n), {'family': 'monospace', 'size': 16}, ha='center', va='top')\n",
    "\n",
    "plt.savefig('1-example_sequences.pdf', bbox_inches='tight', pad_inches=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "match_length = 100\n",
    "crop = match_length/5\n",
    "def random_walk(N):\n",
    "    return np.cumsum(np.random.random_integers(-1, 1, N))/np.log(N)\n",
    "def random_sine(N):\n",
    "    return np.sin(np.linspace(0, 5*np.pi, N)*np.random.uniform(.9, 1.1) + np.random.uniform(0, 2*np.pi))\n",
    "\n",
    "match = random_sine(match_length + match_length/10)\n",
    "query = np.interp(np.arange(match_length),\n",
    "                  np.arange(match_length + match_length/10),\n",
    "                  match + .5*random_walk(match_length + match_length/10))\n",
    "match = match[match_length/10:] + .5*random_walk(match_length)\n",
    "match = (match - match.mean())/match.std()\n",
    "query = (query - query.mean())/query.std()\n",
    "\n",
    "D = np.subtract.outer(match, query[crop/2:-crop/2])**2\n",
    "p, q, score = djitw.dtw(D, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = 3\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(query - query.max(), BLUE, lw=2)\n",
    "\n",
    "for n in range(0, match_length, ds) + [match_length - 1]:\n",
    "    plt.plot([n, n], [match[n] - match.min(), query[n] - query.max()], 'k:', lw=2)\n",
    "    \n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_unwarped.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(match - match.min(), GREEN, lw=2)\n",
    "plt.plot(np.arange(crop/2, match_length - crop/2),\n",
    "         query[crop/2:-crop/2] - query[crop/2:-crop/2].max(), BLUE, lw=2)\n",
    "\n",
    "for p_n, q_n in zip(p[::ds], q[::ds]):\n",
    "    \n",
    "    plt.plot([p_n, q_n + crop/2],\n",
    "             [match[p_n] - match.min(), query[crop/2:-crop/2][q_n] - query[crop/2:-crop/2].max()],\n",
    "             'k:', lw=2)\n",
    "\n",
    "plt.plot([p[-1], q[-1] + crop/2],\n",
    "         [match[p[-1]] - match.min(), query[crop/2:-crop/2][q[-1]] - query[crop/2:-crop/2].max()],\n",
    "         'k:', lw=2)\n",
    "\n",
    "plt.xlim(-1, plt.axis()[1])\n",
    "plt.axis('off')\n",
    "plt.savefig('1-example_distance_warped.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in xrange(layer_size_a):\n",
    "            for o in xrange(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n",
    "\n",
    "def label(ax, x, y, text, label_size=30, **kwargs):          \n",
    "    plt.text(x, y, text, {'size': label_size},\n",
    "             va='center', ha='center', zorder=10, **kwargs)\n",
    "\n",
    "def heaviside(ax, left, right, bottom, top):\n",
    "    middle = left + (right - left)/2.\n",
    "    for x, y in zip([[left, middle], [middle, middle], [middle, right]], \n",
    "                    [[bottom, bottom], [bottom, top], [top, top]]):\n",
    "        line = plt.Line2D(x, y, c='k', lw=2, zorder=10)\n",
    "        ax.add_artist(line)\n",
    "\n",
    "plt.figure(figsize=(FIGSIZE[0], (1 - .16)*FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "draw_neural_net(ax, .1, .9, .0, 1., [3, 1])\n",
    "\n",
    "label(ax, .1, .83333, '$x[1]$')\n",
    "label(ax, .1, .5, '$x[2]$')\n",
    "label(ax, .1, .16666, '$x[3]$')\n",
    "\n",
    "label(ax, .5, .71, '$w[1]$', rotation=-24)\n",
    "label(ax, .5, .535, '$w[2]$')\n",
    "label(ax, .5, .375, '$w[3]$', rotation=24)\n",
    "\n",
    "b_coords = (.6, .2)\n",
    "circle = plt.Circle(b_coords, 1./3./4.,\n",
    "                    color='w', ec='k', zorder=4)\n",
    "plt.gca().add_artist(circle)\n",
    "label(ax, b_coords[0], b_coords[1], '$b$', 36)\n",
    "line = plt.Line2D([b_coords[0], .9], [b_coords[1], .5], c='k')\n",
    "ax.add_artist(line)\n",
    "\n",
    "heaviside(ax, .842, .958, .46, .54)\n",
    "\n",
    "plt.ylim([.08, .92])\n",
    "plt.axis('off')\n",
    "plt.savefig('2-perceptron.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(FIGSIZE[0], .71*FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "\n",
    "circle_radius = .04\n",
    "circle_spacing = .09\n",
    "\n",
    "def circle_grid(ax, size, left, bottom, color='w', zorder=4, **kwargs):\n",
    "    for x in range(size[0]):\n",
    "        for y in range(size[1]):\n",
    "            circle = plt.Circle((x*circle_spacing + left, y*circle_spacing + bottom),\n",
    "                                circle_radius, color=color, ec='k', zorder=zorder - x - y, **kwargs)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "input_left, input_bottom = .05, .05\n",
    "output_left, output_bottom = .65, input_bottom + 3.85*circle_spacing\n",
    "circle_grid(ax, (6, 6), input_left, input_bottom)\n",
    "circle_grid(ax, (4, 4), output_left, output_bottom, color='none', zorder=35, alpha=.3)\n",
    "circle_grid(ax, (3, 3), input_left + 2*circle_spacing, input_bottom + 2*circle_spacing, GREEN, zorder=30)\n",
    "circle_grid(ax, (1, 1), output_left + 2*circle_spacing, output_bottom + 2*circle_spacing, GREEN, zorder=40)\n",
    "\n",
    "ffdeg = circle_radius*np.sqrt(2)/2\n",
    "for x in range(3):\n",
    "    for y in range(3):\n",
    "        line = plt.Line2D([input_left + 2*circle_spacing + x*circle_spacing,\n",
    "                           output_left + 2*circle_spacing],\n",
    "                          [input_bottom + 2*circle_spacing + y*circle_spacing,\n",
    "                           output_bottom + 2*circle_spacing], c='k', zorder=30 - x - y - 1)\n",
    "        ax.add_artist(line)\n",
    "plt.axis([0, .97, 0, .71])\n",
    "plt.axis('off')\n",
    "plt.savefig('2-convolution.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "def f(x):\n",
    "    return x**2\n",
    "def df(x):\n",
    "    return 2*x\n",
    "x = np.linspace(-1, 1, 100)\n",
    "x_init = .7\n",
    "\n",
    "for n, lr in enumerate([1.035, .9, .4, .08]):\n",
    "    plt.subplot(2, 2, n + 1)\n",
    "    plt.plot(x, f(x), BLUE, lw=2)\n",
    "    x_current = x_init\n",
    "    for i in range(5):\n",
    "        x_new = x_current - lr*df(x_current)\n",
    "        plt.plot([x_current, x_new], [f(x_current), f(x_new)], 'k:')\n",
    "        plt.plot([x_current, x_new], [f(x_current), f(x_new)], 'k.', ms=10)\n",
    "        x_current = x_new\n",
    "    plt.ylim(-.01, 1.)\n",
    "    plt.axis('off')\n",
    "plt.savefig('2-learning_rate.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import bayes_opt\n",
    "import matplotlib.gridspec\n",
    "\n",
    "def target(x):\n",
    "    return (-3*(x - .7)**2) + .3*(np.sin(10*x**2) + 3)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = target(x)\n",
    "\n",
    "bo = bayes_opt.BayesianOptimization(target, {'x': (0, 1)}, False)\n",
    "\n",
    "gp_params = {'corr': 'squared_exponential'}\n",
    "bo.initialize(dict((target(n), {'x': n}) for n in [.05, .4, .7, .97]))\n",
    "bo.maximize(init_points=0, n_iter=0, acq='ei', **gp_params)\n",
    "\n",
    "def posterior(bo, xmin=-2, xmax=10):\n",
    "    xmin, xmax = 0, 1\n",
    "    bo.gp.fit(bo.X, bo.Y)\n",
    "    mu, sigma2 = bo.gp.predict(np.linspace(xmin, xmax, 1000).reshape(-1, 1), eval_MSE=True)\n",
    "    return mu, np.sqrt(sigma2)\n",
    "\n",
    "fig = plt.figure(figsize=FIGSIZE)\n",
    "\n",
    "gs = matplotlib.gridspec.GridSpec(2, 1, height_ratios=[3, 1]) \n",
    "ax = plt.subplot(gs[0])\n",
    "\n",
    "mu, sigma = posterior(bo)\n",
    "ax.plot(x, y, BLUE, linewidth=2)\n",
    "ax.plot(bo.X.flatten(), bo.Y, 'k.', markersize=20)\n",
    "\n",
    "ax.fill(np.concatenate([x, x[::-1]]), \n",
    "          np.concatenate([mu - sigma, (mu + sigma)[::-1]]),\n",
    "          fc=GREY, ec='None')\n",
    "ax.axis('off')\n",
    "ax.set_title('Objective')\n",
    "ax.set_ylim([y.min(), y.max()*1.1])\n",
    "\n",
    "ax.set_xlim((0, 1))\n",
    "\n",
    "ax = plt.subplot(gs[1])\n",
    "utility = bo.util.utility(x.reshape((-1, 1)), bo.gp, 0)\n",
    "ax.fill_between(x, utility, facecolor=GREEN, edgecolor='none')\n",
    "ax.set_xlim((0, 1))\n",
    "ax.axis('off')\n",
    "ax.set_title('Expected Improvement')\n",
    "plt.savefig('2-bayesian_optimization.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "duration = 5\n",
    "a, fs = librosa.load('data/2_song.mp3', offset=.25, duration=duration)\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plot_fs = 1000\n",
    "plt.plot(np.linspace(0, duration, duration*plot_fs), librosa.resample(a, fs, plot_fs), BLUE, lw=.2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1])\n",
    "plt.savefig('2-audio_signal.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "\n",
    "tbl_f = np.asarray(\n",
    "    [20, 25, 31.5, 40, 50, 63, 80, 100, 125, 160, 200, 250, 315, 400,\n",
    "     500, 630, 800, 1000, 1250, 1600, 2000, 2500, 3150, 4000, 5000, 6300,\n",
    "     8000, 10000, 12500])\n",
    "tbl_alpha_f = np.asarray(\n",
    "    [0.532, 0.506, 0.480, 0.455, 0.432, 0.409, 0.387, 0.367, 0.349, 0.330,\n",
    "     0.315, 0.301, 0.288, 0.276, 0.267, 0.259, 0.253, 0.250, 0.246, 0.244,\n",
    "     0.243, 0.243, 0.243, 0.242, 0.242, 0.245, 0.254, 0.271, 0.301])\n",
    "tbl_L_U = np.asarray(\n",
    "    [-31.6, -27.2, -23.0, -19.1, -15.9, -13.0, -10.3, -8.1, -6.2, -4.5,\n",
    "     -3.1, -2.0, -1.1, -0.4, 0.0, 0.3, 0.5, 0.0, -2.7, -4.1, -1.0, 1.7,\n",
    "     2.5, 1.2, -2.1, -7.1, -11.2, -10.7, -3.1])\n",
    "tbl_T_f = np.asarray(\n",
    "    [78.5, 68.7, 59.5, 51.1, 44.0, 37.5, 31.5, 26.5, 22.1, 17.9, 14.4,\n",
    "     11.4, 8.6, 6.2, 4.4, 3.0, 2.2, 2.4, 3.5, 1.7, -1.3, -4.2, -6.0, -5.4,\n",
    "     -1.5, 6.0, 12.6, 13.9, 12.3])\n",
    "\n",
    "def iso226_spl_contour(f, L_N=40):\n",
    "    A_f = (4.47E-3*(10.0**(0.025*L_N)-1.15) +\n",
    "           (0.4*10.0**((tbl_T_f+tbl_L_U)/10.0-9.0))**tbl_alpha_f)\n",
    "    return scipy.interpolate.InterpolatedUnivariateSpline(\n",
    "        tbl_f, (10.0/tbl_alpha_f)*np.log10(A_f) - tbl_L_U + 94.0, k=3)(f)\n",
    "\n",
    "f = np.logspace(np.log10(20), np.log10(12500), 100, base=10)\n",
    "l = iso226_spl_contour(f)\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.semilogx(f, l, BLUE, lw=2)\n",
    "plt.xlim([15, 15000])\n",
    "plt.xticks([30, 100, 300, 1000, 3000, 10000],\n",
    "           [30, 100, 300, 1000, 3000, 10000])\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Sound Pressure Level (dB)')\n",
    "plt.savefig('2-equal_loudness.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "piano = pretty_midi.PrettyMIDI()\n",
    "i = pretty_midi.Instrument(0, False)\n",
    "i.notes.append(pretty_midi.Note(100, 48, 0., 1.))\n",
    "piano.instruments.append(i)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(piano.fluidsynth(8000)[400:600], BLUE, lw=2)\n",
    "\n",
    "guitar = pretty_midi.PrettyMIDI()\n",
    "i = pretty_midi.Instrument(41, False)\n",
    "i.notes.append(pretty_midi.Note(100, 48, 0., 1.))\n",
    "piano.instruments.append(i)\n",
    "plt.plot(piano.fluidsynth(8000)[400:600], GREEN, lw=2)\n",
    "sns.despine()\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.ylim([-1, 1])\n",
    "plt.xticks(np.arange(0, 201, 50), np.arange(0, 201, 50)/8.)\n",
    "plt.savefig('2-timbres.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=FIGSIZE)\n",
    "A = np.abs(np.fft.rfft(a))\n",
    "N = A.shape[0]\n",
    "#A /= N\n",
    "A = A[:5001]\n",
    "plt.xticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "           100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/N/100.).astype(int))\n",
    "plt.plot(A, BLUE, lw=.5)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.savefig('2-spectrum.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = np.abs(librosa.stft(a))[:93]\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.5))\n",
    "    plt.yticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "               100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/1024./100.).astype(int))\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.savefig('2-spectrogram.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = librosa.logamplitude(A)\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.5))\n",
    "    plt.yticks(np.arange(0, A.shape[0], A.shape[0]/4),\n",
    "               100*np.ceil(22050*np.arange(0, A.shape[0], A.shape[0]/4)/1024./100.).astype(int))\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.savefig('2-log_spectrogram.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    A = librosa.logamplitude(np.abs(librosa.cqt(a, fmin=librosa.midi_to_hz(36), n_bins=48, real=False)))\n",
    "    plt.imshow(A, aspect='auto', origin='lower', cmap=plt.cm.hot, interpolation='none',\n",
    "               vmin=np.percentile(A, 10), vmax=np.percentile(A, 99.9))\n",
    "    plt.yticks(range(0, 48, 12), [librosa.midi_to_note(n) for n in range(36, 36 + 48, 12)])\n",
    "    plt.xticks(np.arange(0, A.shape[1], A.shape[1]/5), np.arange(6))\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Note')\n",
    "    plt.savefig('2-cqt.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signal1 = np.array([509, 113, -229, 253, -96, -195, 180, -303, -361, 17,\n",
    "                    -13, 242, 14, -230, 300, 89, -112, -236, -298])\n",
    "signal2 = np.array([543, 401, 122, -288, 62, 259, 180, -72, -336, 10,\n",
    "                    223, 263, 35, -345, 68, 400, 38, -109, -301])\n",
    "q = [0, 1, 2, 3, 4, 5, 6, 7, 7, 7, 8, 8, 9, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 18]\n",
    "p = [0, 0, 1, 2, 3, 3, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 12, 13, 14, 14, 15, 16, 17, 18]\n",
    "with sns.axes_style('ticks'):\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    plt.plot(signal1, lw=2, c=BLUE)\n",
    "    plt.plot(signal1, '.', ms=10, c=BLUE)\n",
    "    plt.plot(signal2 + 1000, lw=2, c=GREEN)\n",
    "    plt.plot(signal2 + 1000, '.', ms=10, c=GREEN)\n",
    "    for p_n, q_n in zip(p, q):\n",
    "        plt.plot([p_n, q_n],  [signal1[p_n], signal2[q_n] + 1000], 'k:', lw=2)\n",
    "    ax = plt.gca()\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    sns.despine(left=True)\n",
    "    plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.xlim([-.1, 18.1])\n",
    "    plt.savefig('2-example_dtw_sequences.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure(figsize=FIGSIZE)\n",
    "    dist = scipy.spatial.distance.cdist(signal1.reshape(-1, 1), signal2.reshape(-1, 1))\n",
    "    plt.imshow(dist, cmap=plt.cm.hot, interpolation='nearest')\n",
    "    axis = plt.axis()\n",
    "    for x, y in zip(q, p):\n",
    "        plt.plot([x - .5, x - .5, x + .5, x + .5, x - .5], [y - .5, y + .5, y + .5, y - .5, y - .5], 'w')\n",
    "    plt.axis(axis)\n",
    "    plt.xticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.yticks(range(0, 19, 3), range(1, 20, 3))\n",
    "    plt.savefig('2-example_dtw_matrix.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ALIGNMENT_SEARCH_PATH = '/Users/craffel/Documents/projects/alignment-search/'\n",
    "sys.path.append(ALIGNMENT_SEARCH_PATH)\n",
    "import corrupt_midi\n",
    "import create_data\n",
    "import find_best_aligners\n",
    "import db_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some utility functions\n",
    "def compute_cqt(audio_data):\n",
    "    \"\"\" Compute the log-magnitude L2 normalized CQT \"\"\"\n",
    "    cqt, times = create_data.extract_cqt(audio_data)\n",
    "    cqt = librosa.logamplitude(cqt, ref_power=cqt.max())\n",
    "    return librosa.util.normalize(cqt, 2).T, times\n",
    "def display_cqt(cqt):\n",
    "    \"\"\" Plot a CQT with sane defaults \"\"\"\n",
    "    plt.imshow(cqt.T, aspect='auto', interpolation='nearest',\n",
    "               origin='lower', cmap=plt.cm.hot,\n",
    "               vmin=np.percentile(cqt, 1), vmax=np.percentile(cqt, 99))\n",
    "    plt.yticks(range(0, 48, 12), [librosa.midi_to_note(n) for n in range(36, 36 + 48, 12)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "# Grab a MIDI file from the clean MIDIs we used in this experiment\n",
    "midi_file = os.path.join(ALIGNMENT_SEARCH_PATH, 'data/mid/Come as You Are.mid')\n",
    "# Parse the MIDI file with pretty_midi\n",
    "midi_object = pretty_midi.PrettyMIDI(midi_file)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    # For illustration, we'll plot a CQT of the MIDI object\n",
    "    # before and after corruptions.\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    original_cqt, original_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "    display_cqt(original_cqt)\n",
    "    #plt.title('Original MIDI CQT')\n",
    "    plt.savefig('3-original_cqt.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# This is the wrapper function to apply all of the corruptions \n",
    "# defined in corrupt_midi\n",
    "adjusted_times,  diagnostics = corrupt_midi.corrupt_midi(\n",
    "    midi_object, original_times,\n",
    "    # This defines the extent to which time will be warped\n",
    "    warp_std=20,\n",
    "    # These define how likely we are to crop out sections\n",
    "    # We'll set them to 1 and 0 here for illustration; in the \n",
    "    # paper they are adjusted according to the desired corruption level\n",
    "    start_crop_prob=0., end_crop_prob=0., middle_crop_prob=1.,\n",
    "    # The likelihood that each instrument is removed\n",
    "    remove_inst_prob=.5,\n",
    "    # The likelihood that an instrument's program number is changed\n",
    "    change_inst_prob=1.,\n",
    "    # The standard deviation of velocity adjustment\n",
    "    velocity_std=1.)\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    # Now, we can plot the CQT after corruptions.\n",
    "    plt.figure(figsize=FIGSIZE_FLAT)\n",
    "    corrupted_cqt, corrupted_times = compute_cqt(midi_object.fluidsynth(22050))\n",
    "    display_cqt(corrupted_cqt)\n",
    "    plt.xlabel('Frame')\n",
    "    #plt.title('After corruption')\n",
    "    plt.savefig('3-corrupted_cqt.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "# We can also plot the timing offset, which we will try to reverse\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.plot(original_times, original_times - adjusted_times, BLUE, lw=2)\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.xlabel('Original time')\n",
    "plt.ylabel('Offset from original time')\n",
    "plt.savefig('3-warping.pdf', bbox_inches='tight', pad_inches=0.1)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute a pairwise distance matrix of the original and corrupted CQTs\n",
    "distance_matrix = scipy.spatial.distance.cdist(\n",
    "    original_cqt, corrupted_cqt, 'sqeuclidean')\n",
    "# Compute the lowest-cost path via DTW with \"golden standard\" parameters\n",
    "p, q, score = djitw.dtw(\n",
    "    distance_matrix, .96, np.median(distance_matrix), inplace=0)\n",
    "\n",
    "# Compute the absolute error, clipped to within .5 seconds\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "error = np.abs(np.clip(\n",
    "    corrupted_times[q] - adjusted_times[p], -.5, .5))\n",
    "plt.plot(original_times[p], error, BLUE, lw=2)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Correction error')\n",
    "plt.xlim([0, original_times.max()])\n",
    "plt.ylim([-0.01, .51])\n",
    "plt.savefig('3-correction_error.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in the results from the parameter search experiment\n",
    "params, objectives = db_utils.get_experiment_results(\n",
    "    os.path.join(ALIGNMENT_SEARCH_PATH, 'results/parameter_experiment_gp/*.json'))\n",
    "# Truncate to the top 20 results\n",
    "good = np.argsort(objectives)[:10]\n",
    "params = [params[n] for n in good]\n",
    "objectives = [objectives[n] for n in good]\n",
    "# Pretty-print using tabulate\n",
    "for param, objective in zip(params, objectives):\n",
    "    param['objective'] = objective\n",
    "header_names = collections.OrderedDict([\n",
    "    ('add_pen', '$\\phi$ Median Scale'),\n",
    "    ('standardize', 'Standardize?'),\n",
    "    ('gully', 'Gully $g$'),\n",
    "    ('objective', 'Mean Error')])\n",
    "def yes_no(x):\n",
    "    if isinstance(x, bool):\n",
    "        if x:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    else:\n",
    "        return x\n",
    "print tabulate.tabulate([collections.OrderedDict([(k, yes_no(p[k])) for k in header_names]) for p in params],\n",
    "                        headers=header_names, tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load in all confidence reporting experiment trials\n",
    "trials = []\n",
    "for trial_file in glob.glob(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/confidence_experiment/*.json')):\n",
    "    with open(trial_file) as f:\n",
    "        trials.append(json.load(f))\n",
    "# Retrieve the lowest-achieved mean absolute error\n",
    "best_easy_error = objectives[0]\n",
    "# Retrieve the confidence reporting trial for this system\n",
    "best_trial = [t for t in trials\n",
    "               if np.allclose(np.mean(t['results']['easy_errors']),\n",
    "                              best_easy_error)][0]\n",
    "# Retrieve the results from this trial\n",
    "best_result = best_trial['results']\n",
    "\n",
    "# Plot a scatter plot of mean alignment error vs. confidence score\n",
    "errors = np.array(best_result['hard_errors'] + best_result['easy_errors'])\n",
    "scores = np.array(best_result['hard_penalty_len_norm_mean_norm_scores'] +\n",
    "                  best_result['easy_penalty_len_norm_mean_norm_scores'])\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "plt.scatter(errors, scores, marker='+', c='black', alpha=.3, s=40)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.ylim(0., 1.1)\n",
    "plt.xlim(.9*np.min(errors), np.max(errors)*1.1)\n",
    "plt.xlabel('Alignment error')\n",
    "plt.ylabel('Normalized DTW distance')\n",
    "plt.xticks([.01, .025, .05, .1, .25, .5], [.01, .025, .05, .1, .25, .5])\n",
    "plt.savefig('3-correlation.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/alignment_ratings.csv')) as f:\n",
    "    reader = csv.reader(f)\n",
    "    # Cast each entry in each row to the correct type\n",
    "    ratings = [[int(alignment_id), int(rating), np.clip(2*(1 - float(score)), 0, 1), note]\n",
    "               for alignment_id, rating, score, note in reader]\n",
    "\n",
    "# We made notes about each alignment, too.\n",
    "# Here are all the alignments where a transcription was matched to a remix\n",
    "remixes = [r[1:] for r in ratings if ('remix' in r[-1].lower())]\n",
    "remixes.sort(key = lambda x: -x[1])\n",
    "print tabulate.tabulate(remixes, headers=['Rating', 'Confidence Score', 'Note'], tablefmt='latex_booktabs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a histogram for each rating\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "data = [np.array([r[2] for r in ratings if r[1] == n]) for n in [1, 2, 3, 4, 5]]\n",
    "violins = plt.violinplot(\n",
    "    data, showextrema=False, showmeans=False,\n",
    "    widths=[float(len(d))/max(len(d) for d in data) for d in data])\n",
    "patches = plt.boxplot(data, showmeans=False, showcaps=False, showfliers=False, \n",
    "                      patch_artist=True, widths=.1)\n",
    "for line in patches['whiskers']:\n",
    "    line.set_visible(False)\n",
    "for box in patches['boxes']:\n",
    "    box.set_facecolor('None')\n",
    "    box.set_alpha(.5)\n",
    "    box.set_joinstyle('round')\n",
    "    box.set_facecolor('w')\n",
    "    box.set_edgecolor('k')\n",
    "for line in patches['medians']:\n",
    "    line.set_color('black')\n",
    "for body in violins['bodies']:\n",
    "    body.set_alpha(.8)\n",
    "for n in [0, 1]:\n",
    "    violins['bodies'][n].set_facecolor(BLUE)\n",
    "for n in [2, 3, 4]:\n",
    "    violins['bodies'][n].set_facecolor(GREEN)\n",
    "plt.xticks(\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5])\n",
    "    #['Wrong song', 'Bad alignment', 'Sloppy', 'Embellishments', 'Perfect'],\n",
    "    #rotation=20)\n",
    "plt.xlim([.5, 5.5])\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Confidence score')\n",
    "plt.legend(handles=[matplotlib.patches.Patch(color=BLUE, label='Incorrect'),\n",
    "                    matplotlib.patches.Patch(color=GREEN, label='Correct')],\n",
    "           loc='upper left')\n",
    "plt.ylim(-.03, 1.03)\n",
    "plt.savefig('3-violin.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pretty_cqt(audio_data, fs=feature_extraction.AUDIO_FS):\n",
    "    gram = np.abs(librosa.cqt(\n",
    "        audio_data, sr=fs, hop_length=feature_extraction.AUDIO_HOP,\n",
    "        fmin=librosa.midi_to_hz(feature_extraction.NOTE_START),\n",
    "        n_bins=feature_extraction.N_NOTES, real=False))\n",
    "    # Compute log amplitude\n",
    "    gram = librosa.logamplitude(gram**2, ref_power=gram.max())\n",
    "    # Transpose so that rows are samples\n",
    "    gram = gram.T\n",
    "    # and L2 normalize\n",
    "    #gram = librosa.util.normalize(gram, axis=1)\n",
    "    # and convert to float32\n",
    "    return gram.astype(np.float32)\n",
    "audio, fs = librosa.load('data/4-mmt.wav', sr=feature_extraction.AUDIO_FS)\n",
    "audio_gram = pretty_cqt(audio)\n",
    "m = pretty_midi.PrettyMIDI('data/4-mmt.mid')\n",
    "midi_audio_aligned = m.fluidsynth(feature_extraction.AUDIO_FS)\n",
    "# Adjust to the same size as audio\n",
    "if midi_audio_aligned.shape[0] > audio.shape[0]:\n",
    "    midi_audio_aligned = midi_audio_aligned[:audio.shape[0]]\n",
    "else:\n",
    "    trim_amount = audio.shape[0] - midi_audio_aligned.shape[0]\n",
    "    midi_audio_aligned = np.append(midi_audio_aligned,\n",
    "                                   np.zeros(trim_amount))\n",
    "midi_aligned_gram = pretty_cqt(midi_audio_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_brace(ax, left, right, bottom, top, beta=10., fliplr=False, flipud=False):\n",
    "    if flipud:\n",
    "        bottom, left = left, bottom\n",
    "        right, top = top, right\n",
    "    half_y = (top + bottom)/2.\n",
    "    half_range = np.linspace(bottom, half_y, 100)\n",
    "    x = (1/(1. + np.exp(beta*(half_range - bottom)))\n",
    "         + 1/(1. + np.exp(beta*(half_range - half_y))))\n",
    "    x = np.concatenate((x, x[::-1]))\n",
    "    if fliplr:\n",
    "        x = -x + 1\n",
    "    else:\n",
    "        x = x - 1\n",
    "    x = x*(right - left) + (left + right)/2.\n",
    "    if flipud:\n",
    "        ax.plot(np.linspace(bottom, top, 200), x, 'k', lw=2)\n",
    "    else:\n",
    "        ax.plot(x, np.linspace(bottom, top, 200), 'k', lw=2)\n",
    "\n",
    "fig = plt.figure(figsize=(FIGSIZE[0], FIGSIZE[0]))\n",
    "ax = plt.gca()\n",
    "draw_neural_net(ax, .3, .6, .51, .79, [4, 7, 5, 3])\n",
    "ax.text(.32, .76, '$f$', ha='center', va='center', fontdict={'size': 30})\n",
    "draw_neural_net(ax, .3, .6, .21, .49, [4, 6, 7, 3])\n",
    "ax.text(.32, .46, '$g$', ha='center', va='center', fontdict={'size': 30})\n",
    "\n",
    "ax.annotate('', xy=(.15, .8),  xycoords='data',\n",
    "            xytext=(.25, .65), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .255, .285, .58, .72, 1000.)\n",
    "\n",
    "ax.annotate('', xy=(.15, .2),  xycoords='data',\n",
    "            xytext=(.25, .35), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=0,angleB=90,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .255, .285, .28, .42, 1000.)\n",
    "\n",
    "ax.annotate('', xy=(.65, .65),  xycoords='data',\n",
    "            xytext=(.8, .55), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=90,angleB=0,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .615, .645, .6, .7, 1000., 1)\n",
    "\n",
    "ax.annotate('', xy=(.65, .35),  xycoords='data',\n",
    "            xytext=(.8, .45), textcoords=None,\n",
    "            arrowprops=dict(arrowstyle=\"<-\",\n",
    "                            connectionstyle=\"angle,angleA=90,angleB=0,rad=10\",\n",
    "                            lw=2),\n",
    "            size=40)\n",
    "draw_brace(ax, .615, .645, .3, .4, 1000., 1)\n",
    "\n",
    "ax.imshow(audio_gram[500:700].T, interpolation='nearest', aspect='auto', cmap=plt.cm.hot,\n",
    "          origin='lower', extent=(0, 1, .8, 1), vmin=np.percentile(audio_gram, 15))\n",
    "ax.imshow(midi_aligned_gram[500:700].T, interpolation='nearest', aspect='auto', cmap=plt.cm.hot,\n",
    "          origin='lower', extent=(0, 1, 0, .2), vmin=np.percentile(midi_aligned_gram, 15))\n",
    "\n",
    "ax.imshow(np.array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0]]), cmap=plt.cm.hot,\n",
    "          extent=(.6, 1., .46, .485), interpolation='nearest')\n",
    "\n",
    "ax.imshow(np.array([[1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0]]), cmap=plt.cm.hot,\n",
    "          extent=(.6, 1., .51, .535), interpolation='nearest')\n",
    "\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.13, 0.001), 0.04, 0.2, alpha=.6, fc='w'))\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.13, 0.8), 0.04, 0.2, alpha=.6, fc='w'))\n",
    "\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.6, 0.46), 0.4, 0.025, fc='None', ec='k'))\n",
    "ax.add_patch(matplotlib.patches.Rectangle((0.6, 0.51), 0.4, 0.025, fc='None', ec='k'))\n",
    "\n",
    "ax.axis([0, 1, 0, 1])\n",
    "ax.axis('off')\n",
    "plt.savefig('4-hashing_schematic.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hash_a = np.array([1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0], dtype=bool)\n",
    "hash_b = np.array([1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0], dtype=bool)\n",
    "xor = np.bitwise_xor(hash_a, hash_b)\n",
    "popcnt = np.sum(xor)\n",
    "\n",
    "plt.figure(figsize=FIGSIZE)\n",
    "eps = .002\n",
    "ax = plt.gca()\n",
    "\n",
    "hash_l = .24\n",
    "hash_r = .995\n",
    "vheight = (hash_l - hash_r)/16\n",
    "\n",
    "plt.imshow(hash_a[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1., 1 - vheight + eps), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - vheight), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.imshow(hash_b[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1 - 3*vheight/2 + eps, 1 - 5*vheight/2), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - 5*vheight/2), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.imshow(xor[np.newaxis], interpolation='nearest',\n",
    "           extent=(hash_l, hash_r, 1 - 3*vheight, 1 - 4*vheight), cmap=plt.cm.hot)\n",
    "ax.add_patch(plt.Rectangle((hash_l, 1 - 4*vheight), hash_r - hash_l, vheight, fc='none'))\n",
    "\n",
    "plt.plot([hash_l*.7, hash_r], [1 - 11*vheight/4, 1 - 11*vheight/4], 'k', lw=2)\n",
    "\n",
    "ax.add_patch(plt.Circle((hash_l*.8, 1 - 2*vheight), vheight/2, fc='none', lw=2))\n",
    "plt.plot((hash_l*.8, hash_l*.8), (1 - 3*vheight/2, 1 - 5*vheight/2), 'k', lw=2)\n",
    "plt.plot((hash_l*.8 - vheight/2, hash_l*.8 + vheight/2), (1 - 2*vheight, 1 - 2*vheight), 'k', lw=2)\n",
    "\n",
    "plt.text(hash_l/2, 1 - 7*vheight/2 + .003, 'POPCNT(', va='center', ha='center',\n",
    "         fontdict={'size': 28, 'family': 'monospace'})\n",
    "plt.text(hash_r + (1 - hash_r)/2., 1 - 7*vheight/2 + .003, ')$\\;$=$\\;${}'.format(popcnt),\n",
    "         va='center', ha='left', fontdict={'size': 28, 'family': 'monospace'})\n",
    "\n",
    "plt.axis([0, 1, 1 - 4*vheight + .01, 1])\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('4-popcnt.pdf',  bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many false positives/negatives do we get from thresholding the alignment scores at .5?\n",
    "with open(os.path.join(ALIGNMENT_SEARCH_PATH, 'results/alignment_ratings.csv')) as f:\n",
    "    reader = csv.reader(f)\n",
    "    # Cast each entry in each row to the correct type\n",
    "    ratings = [[int(alignment_id), int(rating), np.clip(2*(1 - float(score)), 0, 1), note]\n",
    "               for alignment_id, rating, score, note in reader]\n",
    "print np.sum([r[1] <= 2 and r[2] >= .5 for r in ratings])\n",
    "print np.sum([r[1] >= 3 and r[2] <= .5 for r in ratings])\n",
    "print np.sum([r[1] >= 3 and r[2] >= .5 for r in ratings])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
