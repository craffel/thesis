\chapter{Tools} \label{ch:tools}

Throughout this thesis, we will use a common collection of tools to help solve problems of interest.
Broadly speaking, we will make use of techniques from the fields of machine learning and signal processing.
In this chapter, we give a high-level overview of these fields and a more specific definition of the various techniques we will utilize.

\section{Machine Learning}

Machine learning is broadly defined as a suite of methods for enabling computers to carry out particular tasks without being explicitly programmed to do so.
Such methods make use of a collection of data, from which patterns or the desired behaviors are automatically determined.
In this sense, machine learning techniques allow computers to ``learn'' the correct procedure based on the data provided.
In addition to data, machine learning algorithms also often require an objective which quantifies the extent to which they are successfully carrying out a task.
This objective function allows them to be optimized in order to maximize their performance.

Traditionally, machine learning techniques are divided into three types: Supervised, unsupervised, and reinforcement learning.
Supervised learning requires a collection of training data that specifies both the input to the algorithm and the desired output.
Unsupervised learning, on the other hand, does not utilize target output data, and thus is limited to finding structure in the input data.
Finally, reinforcement learning refers to the broader problem of determining a policy to respond to input data in a dynamic ``environment'' based on a potentially rare signal which tells the algorithm whether it is successful or not.
All of the problems in this thesis fall into the category of supervised learing, so we will not discuss unsupervised or reinforcement learning further.

\subsection{Supervised Learning}

In the supervised setting, our machine learning algorithm produces a function $f$ (called a {\em model}) which, given input $x$ and the function's parameters $\theta$, produces an output $\hat{y}$:

\begin{equation}
\hat{y} = f(x, \theta)
\end{equation}

Supervised learning requires a training set $\mathcal{S}$ of input-target pairs $(x_1, y_1), (x_2, y_2), \ldots (x_{|S|}, y_{|s|}$, where $x_n \in \mathcal{X}$ and $y_n \in \mathcal{Y}$.
We assume that these pairs are drawn from an unknown joint probability distribution $p(x, y)$, of which the only information we explicitly know is the training set $\mathcal{S}$.
The goal of a supervised learning algorithm is to capture the probability distribution $p(x, y)$ with $f$ by adjusting the parameters $\theta$ based solely on $\mathcal{S}$.

One way to formulate this goal is to state that for a sample from $p(x, y)$ which is not in $\mathcal{S}$, the function $f$ should produce the correct output.
Of course, because we are only given the samples in $\mathcal{S}$, the parameters $\theta$ must be optimized solely according the training pairs in $\mathcal{S}$.
This approach, where $f$ is used directly to produce the predicted value for $y$, is referred to as discriminant training.
An alternative approach, called probabilistic training, is to use $f$ to model $p(x, y)$ by estimating $p(y | x)$ and then choosing the most probable $y$.
In either case, choosing $f$ typically involves using a task-specific ``loss function'' $L$ which computes a nonnegative scalar value which measures the extent to which $\hat{y}$ agress with $y$.
Ideally, minimizing this loss over the training set by adjusting $\theta$ will yield an $f$ which closely approximates $p(x, y)$.

The choice of a loss function will depend on the characteristics of the problem, in particular the target space $\mathcal{Y}$.
For example, in {\em classification} problems, the targets $y$ may take one of $K$ discrete values.
A natural loss function in this case is the zero-one loss

\begin{equation}
L(y, \hat{y}) = \begin{cases}
1,& \hat{y} = y\\
0,& \hat{y} \ne y
\end{cases}
\end{equation}

In {\em regression} problems, the targets are continuously valued, and a common loss function is the squared error

\begin{equation}
L(y, \hat{y}) = (y - \hat{y})^2
\end{equation}

Note that in both cases when $y = \hat{y}$, $L = 0$; this is a common property of loss functions.

In general, a suitable goal for training an unsupervised learning algorithm is to adjust $\theta$ to minimize the average loss over the training set:

\begin{equation}
\frac{1}{|\mathcal{S}|} \sum_{(x, y) \in \mathcal{S}} L(y, f(x, \theta))
\end{equation}

Minimizing this average loss is equivalent to minimizing the empirical risk of $f$.
A common paradigm is to compute the derivative of the loss function $L$ with respect to the model parameters $\theta$ and use this derivative information to incrementally change $\theta$ to make $L$ smaller.
In this case, it is beneficial to have a loss function which is continuous and smooth, which precludes the use of loss functions like the zero-one loss.
A common solution to this problem is to use a surrogate loss function which has the desired properties (e.g.\ smoothness) and whose minimization will also minimize $L$.

There are supervised learning methods which do not follow the above framework.
For example, the k-nearest neighbors algorithm is a classification algorithm which labels its input by assigning it the most common $y$ among the $k$ points in $\mathcal{S}$ which are closest to the input.
This classifier has no loss function or indeed any parameters other than $k$ and $\mathcal{S}$ itself (i.e.\ it is nonparametric).
However, all of the methods we will utilize in this thesis follow the recipe of defining a model with parameters $\theta$ which are adjusted by miniimzing the average loss over $\mathcal{S}$.

\subsection{Sequential Data}

A common scenario is that the data space $\mathcal{X}$ is fixed-dimensional, e.g.\ $\mathcal{X} \in \mathbb{R}^{D_1 \times D_2 \times \cdots D_N}$.
However, in some cases, one (or more) dimensions may vary in size.
An important example of this is sequential data, where a ``temporal'' dimension can differ between examples.
In addition, for real-world data the temporal dimension often contains strong dependencies and correlations.
For some examples of common types of data typically represented as sequences, see \cref{fig:example_sequences}.

An illustrative example is text data where each datapoint is a sentence.
Clearly, the length of each sequence will vary (e.g.\ ``I am happy.'' and ``This sentence is a few words longer.'' differ in length).
In addition, there may be a strong dependency between a given word in a sentence and the words that precede it.
For example, ``I am hungry, please give me'' is much more likely to be followed by the word ``food'' than, say, ``dirt''.

Different possible tasks involving sequential data can be broadly divided into three categories: Sequence classification, embedding, and transduction.
Sequence classification involves applying a single label to entire sequences; for example, classifying which of a finite number of people was speaking in an audio recording of an utterance.
Sequence embedding involves representing sequences as a single point in a fixed-dimensional space with some desired properties.
For example, instead of classifying which person was speaking, we might instead embed audio recordings as vectors in a Euclidean space such that recordings of the same speaker have a small embedded distance and recordings of different speakers have a large distance.
Finally, sequence transduction involves converting an input sequence to a new sequence, potentially of different length and whose elements may lie in a different space.
Speech recognition is an exemplary case, where a sequence of discrete words must be generated based on an audio recording.

\subsection{Neural Networks}

\subsubsection{Backpropagation}

\subsubsection{Recurrent Networks}

\subsubsection{Convolutional Networks}

\subsubsection{Attention}

\subsection{Stochastic Optimization}

\subsection{Bayesian Optimization}

\section{Signal Processing}

\subsection{Audio Signals and Psychoacoustics}

proposal1

\subsection{Time-Frequency Analysis}

\subsection{Dynamic Time Warping}

ismir2015large2, icassp2016optimizing2

\subsubsection{Pruning Methods}

icassp2016pruning1
