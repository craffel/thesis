\chapter{Learning an Efficient Representation for Dynamic Time Warping}
\label{ch:dhs}

The system developed in \cref{ch:dtw} produces a confidence score which proved to be extremely reliable at determining whether or not a MIDI file was a transcription of a given audio file.
The goal of this thesis is to match a large collection of 178,561 MIDI files to corresponding audio recordings.
We cannot rely on any source of metadata from these MIDI files (see \cref{sec:score_overview}), so we must instead utilize a {\em content-based} comparison scheme like the one proposed in \cref{ch:dtw}.
To maximize the chances of finding a matching audio recording for a given MIDI file, we need to use a large and comprehensive pool of audio files.
We use the 994,960 7digital preview clips \cite{schindler2012facilitating} corresponding to the Million Song Dataset (MSD) \cite{bertin2011million}, which consist of (typically) 30 second portions of recordings from the largest standard research corpus of popular music.
A complete search for matches could thus involve 994,960 alignments for each of our 178,561 MIDI files, resulting in 177,661,052,560 comparison.

The method proposed in \cref{ch:dtw} is much too inefficient to be used in this manner.
Under this approach, aligning a typical-length MIDI file to a single audio recording from the MSD takes on average about 132 milliseconds on an Intel Core i7-4930k processor when using an extremely efficient LLVM-compiled DTW routine and a parallelized distance matrix computation.
Matching our entire collection of MIDI files using this approach would therefore take approximately
\begin{equation}
\frac{(.132 \mathrm{\;seconds})(178{,}561 \mathrm{\;MIDI\;files})(994{,}960 \mathrm{\;audio\;files})}{(60 \mathrm{\;seconds})(60 \mathrm{\;minutes})(24 \mathrm{\;hours})(365 \mathrm{\;days})} \approx 745 \mathrm{\;years}
\end{equation}
Clearly, a more efficient approach is warranted.

In fact, the problem of finding the sequence in a large database (here, a collection of audio recordings) which is most similar under DTW distance to a query (here, a MIDI file) is common in the field of data mining \cite{berndt1994using}.
Unsurprisingly, a variety of methods have been proposed for speeding up this task to make it feasible for very large databases.
A pervasive framework is ``pruning'', where a computationally efficient operation is used to discard a large portion of the database and the remaining entries are compared using a more expensive, but highly accurate, method.
Under certain assumptions, there are methods which can achieve {\em exact} pruning (i.e.\ without every erroneously discarding the correct match) of large-scale nearest-neighbor DTW search.
\cite{rakthanmanon2012searching} provides a thorough overview of these techniques and shows that for some problems they can allow exact search of databases with trillions of data points.
However, one of the core assumptions of these methods is that the query is always a subsequence of its correct match, and equivalently that the length of the aligned sequence is known a priori, which does not hold in the setting of MIDI-to-audio matching.
In fact, because the 7digital MP3s are truncated preview clips and MIDI files are usually complete transcriptions, for our problem we nearly always have the opposite case where the correct match is a subsequence of the query.
We therefore cannot leverage these pruning methods for our problem.

One of the reasons DTW-based search is so expensive is that it has $\mathcal{O}(MN)$ complexity, where $M$ and $N$ are the lengths of the two sequences being compared.
Clearly, then, DTW can be made quadratically more efficient by decreasing the number of elements in the sequences being compared.
For example, \cite{keogh2001dimensionality,yi2000fast} proposed downsampling sequences by computing their average over non-overlapping blocks, which for some tasks provided orders of magnitude speedup without dramatically affecting accuracy.
The appropriateness of downsampling sequences depends on the sequences being oversampled (i.e.\ having an unnecessarily high correlation between consecutive sequence elements).

Computing the DTW distance between two sequences also potentially involves computing the pairwise Euclidean distance between all of their elements.
In data mining tasks, entries in sequences are often one-dimensional, so the cost of this operation is usually not considered independent of the overall cost of DTW.
For the time-frequency representation we utilize in \cref{ch:dtw}, our sequences consist of 48-dimensional feature vectors.
As a result, in our problem setting computing the pairwise distance matrix is actually more expensive than finding the lowest-cost path through it because each entry in the distance matrix requires at least $D$ operations, where $D$ is the feature dimensionality.
While computing the distance matrix similarly receives quadratic speed gains when the sequences are downsampled, it also can benefit when a lower-dimensional or otherwise more efficient feature representation is used.

In addition, the ``raw'' representation in which data is initially provided may not produce the most effective measure of similarity under the Euclidian distance utilized by DTW.
More concretely, while the audio-to-synthesized MIDI CQT comparison utilized in \cref{ch:dtw} proved effective, it may be that we are able to transform the individual feature vectors to a space where similarity is better represented so that matching MIDI files and audio recordings have a smaller DTW distance.
Recently, the framework of ``representation learning'' has proven to be effective for this type of problem \cite{bengio2013representation}.
Representation learning utilizes prior knowledge, such as a collection of pairs of known-similar and dissimilar elements, to learn a mapping to a more effective transformed space.
This process is also capable of producing ``mutilmodal'' mappings, i.e.\ transformations which allow the comparison of heterogeneous data.

From the above discussion, it is clear that mapping very long sequences of high-dimensional feature vectors to shorter, lower-dimensional sequences such that similarity is preserved would provide substantial gains when comparing sequences with DTW.
Motivated by this possibility, in this chapter we propose a system with the following capabilities:
\begin{description}
\item[Maps to a Hamming space:] By replacing continuous-valued feature vectors with bitvectors in an embedded Hamming space, computing the distance between a pair of feature vectors simplifies to an exclusive-or followed by a single POPCNT SSE4.2 operation \cite{intel2007programming}, which substantially speeds up distance matrix calculation.
\item[Downsamples sequences:] Rather than creating a one-to-one correspondence between the original featured vectors and mapped bitvectors, groups of subsequent feature vectors are mapped to a single bitvector, giving a quadratic increase in efficiency.
\item[Preserves similarity:] The system is trained with an objective which seeks to produce a mapping where aligned feature vectors from matching sequences have a small Hamming distance in the embedded space, and non-matched feature vectors have a large distance.
\item[Learns its representation:] Our approach is entirely data-driven, which allows it to adapt to different problem settings including multimodal data, as we show in \cref{sec:multimodal}.
\end{description}

In the following section, we describe our model and training approach in detail.
In \cref{sec:dhs_experiment}, we test our system's accuracy on the task of matching MIDI files to the Million Song Dataset.
Finally, we discuss possibilities for improvement in \cref{sec:dhs_discussion}.

\section{Learning to Downsample and Hash}

As a high-level overview, our system will learn a mapping from sequences of feature vectors to downsampled sequences of binary vectors in a Hamming space where similarity is preserved based on a training set of matched and aligned sequences.
This training set can be constructed by obtaining a collection of sequences in which matching pairs are known, and then using DTW to find the optimal alignment of feature vectors in matching sequences.
From this data, we extract groups of sequentially co-occuring feature vectors to construct $\mathcal{P}$, such that $(x, y) \in \mathcal{P}$ indicates that $x$ is a group of feature vectors which is aligned to the group $y$ from a matching sequence.
For example, in the context of MIDI to audio matching, $x$ will be subsequent constant-Q spectra of a synthesized MIDI which are aligned in time to $y$, consisting of co-occuring constant-Q spectra from a matching audio recording.
We then construct $\mathcal{N}$, a set of ``dissimilar'' pairs, by repeatedly randomly choosing two pairs $(x_1, y_1), (x_2, y_2) \in \mathcal{P}$ and swapping to obtain $(x_1, y_2), (x_2, y_1) \in \mathcal{N}$.

Given this training data, our goal is to map sequences of feature vectors to sequences of binary vectors in a Hamming space where groups of sequentially co-occuring vectors in $\mathcal{P}$ have a small distance and groups in $\mathcal{N}$ have a large distance.
Motivated by the multimodal hashing technique of \cite{masci2014multimodal}, we use the following objective function to measure the quality of the mapping:

\begin{equation}
\mathcal{L} = \frac{1}{|\mathcal{P}|} \sum_{(x, y) \in \mathcal{P}} \| f(x) - g(y) \|_2^2  + \frac{\alpha}{|\mathcal{N}|} \sum_{(a, b) \in \mathcal{N}} \max(0, m - \|f(a) - g(b) \|_2)^2
\label{eq:hashing_objective}
\end{equation}

where $f$ and $g$ are learned nonlinear functions, $\alpha$ is a parameter to control the importance of separating dissimilar items, and $m$ is a target separation of dissimilar pairs.
More specifically, if $x, y \in \mathbb{R}^{G \times D}$ where $G$ is the number of subsequent feature vectors which are grouped together (and therefore the downsampling ratio) and $D$ is the feature dimensionality, then $f(x), g(y) \in \mathbb{H}^E$ where $\mathbb{H}^E$ is the Hamming space of dimensionality $E$.
This system is then optimized over $\mathcal{P}$ and $\mathcal{N}$ by to adjust the parameters of $f$ and $g$ such that $\mathcal{L}$ is minimized.
The use of two different functions $f$ and $g$ allows for different mappings to be learned for different types of data; we expect this to be beneficial for our problem setting because synthesized MIDI CQTs and real-world audio CQTs may have different characteristics.
This also allows us to experiment with multimodal data, i.e.\ cases where $x$ and $y$ come from different, and potentially non-comparable, feature spaces.
A visualization of this process is shown in \cref{fig:hashing_schematic}.

\begin{figure}
  \includegraphics[width=\textwidth]{figures/4-hashing_schematic.pdf}
  \caption[Hashing groups of subsequent feature vectors]{Diagram visualizing how subsequent groups of feature vectors are mapped to binary vectors.
Matching sequences of feature vectors which have been aligned in time are shown at the top and bottom.
Co-occuring groups of feature vectors, highlighted in light boxes, are passed through two learned nonlinear functions $f$ and $g$ (visualized as neural network diagrams).
The functions then output a single hash vector each, which are ideally close together in the embedded Hamming space because they represent co-occuring feature vectors from matched and aligned sequences.
For groups of feature vectors from non-matching sequences, the networks are trained to output binary vectors with a large Hamming distance.}
  \label{fig:hashing_schematic}
\end{figure}

After minimizing $\mathcal{L}$ on a training set, sequences of feature vectors in either modality can then be mapped to downsampled sequences of hash vectors using $f$ and $g$.
Once mapped, we can perform DTW much more efficiently to compute a distance between hash sequences, where the Euclidean distance calculation inherent in DTW has been replaced by Hamming distance.
More specifically, we expect a speedup by a factor of up to $G^2 D$, because we have effectively downsampled both sequences by a factor of $G$ and have replaced the $D$-operation Euclidean distance with a Hamming distance calculation.
In practice, the resulting binary vectors can be represented efficiently as unsigned integers, whose Hamming distance can be computed with an exclusive-or operation followed by a call to the POPCNT SSE4.2 instruction \cite{intel2007programming}.
The exclusive-or compares bit-by-bit whether the entries of the binary vectors are equal, and the POPCNT implements a ``population count'' or ``hamming weight'' calculation, which simply counts the number of nonzero bits in the result.
This process is visualized in \cref{fig:popcnt}.
Ideally, utilizing DTW to compare sequences which have been mapped to this efficient representation will effectively recover matching and non-matching sequences.

\begin{figure}
  \includegraphics[width=\textwidth]{figures/4-popcnt.pdf}
  \caption[Computing Hamming distance with XOR and POPCNT]{Computing the Hamming distance between two binary vectors via an exclusive-or followed by a POPCNT instruction.
The exclusive-or of the top two vectors produces the bottom vector, which is $1$ where the input vectors differ and $0$ where they match.
The result of the exclusive-or is passed to the POPCNT SSE4.2 instruction, which simply counts the number of non-zero bits in its input.
These two steps therefore can produce the distance between two binary vectors in two machine instructions.}
  \label{fig:popcnt}
\end{figure}

Given our training procedure, we now need to choose appropriate models for the hashing functions $f$ and $g$.
Neural networks are an attractive choice, because they can in principle be optimized with respect to unusual loss functions like the one defined in \cref{eq:hashing_objective}.
In addition, the suite of tricks discussed in \cref{sec:tricks} can help ensure effective results.

In \cite{masci2014multimodal}, dense feed-forward neural networks are used for the learnable functions $f$ and $g$.
We could potentially utilize this type of network for our hashing and downsampling procedure by concatenating input $x, y \in \mathbb{R}^{G \times D}$ into single-dimensional vectors in $\mathbb{R}^{GD}$.
However, we argue that convolutional networks (discussed in \cref{sec:convolutional_networks}) are a better choice for sequential data for the following reasons:
Sequential data has at least one ordered (temporal) dimension, and in most natural data, the strongest dependencies along the temporal axis are localized.
This is exactly the kind of structure convolutional networks are designed to efficiently exploit.
Furthermore, the pooling layers which are a common ingredient in convolutional networks provide a natural method of downsampling the sequences.
They also allow the network's output a given point in time to depend on a large ``receptive field'' of the input.
In our problem setting, this means that a given hash vector produced by $f$ or $g$ will be affected not only by the corresponding group of $G$ feature vectors but also on a window of feature vectors surrounding it.
For the above reasons, we utilize convolutional networks for the rest of this chapter.

\section{Experiment: MIDI to MSD Matching}
\label{sec:dhs_experiment}

\subsection{Preparing Data}

ismir2015large2

\subsection{System Specifics}

ismir2015large3.2

Receptive field

\subsection{Baseline Methods}

Thresholding CQT PCA
LSH

\subsection{Adapting to Multi-Modal Data}
\label{sec:multimodal}

nips2015accelerating3

\subsection{Results}

ismir2015large4

Add qualitative network behavior plots (deep dream).
Add percentage-below-rank plot.

\section{Discussion}
\label{sec:dhs_discussion}
