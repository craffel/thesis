\chapter{Assembling a Collection of MIDI Files Matched to the Million Song Dataset}
\label{ch:assembling}

Combining the results of \cref{ch:dtw,ch:dhs,ch:pse}, we now have all the ingredients required to efficiently match MIDI files to the Million Song Dataset.
Taken together, these three techniques present a cascade of matching methods, each of which achieves more precision at higher computational cost than the last.
This allows us to quickly discard the vast majority of the dataset before utilizing the expensive, but accurate, DTW operation of \cref{ch:dtw}.
While our main application in this thesis is MIDI-to-audio matching, all of these techniques are learning-based and data-adaptive, so we are optimistic they will be effective in other domains.

In this chapter, we finally utilize these techniques to match our collection of 178,561 MIDI files to the MSD.
In the following section, we discuss the practical implementation of this process, perform a small experiment to verify its performance, and give an overview of the results.
In \cref{sec:deriving}, we quantify the reliability of ground-truth annotations for content-based MIR extracted from this data and discuss further potential applications.
Finally, in \cref{sec:ideas} we wrap up with ideas for additional applications and improvements for our approach.

\section{Matching MIDI Files}

As an overview, our method for matching MIDI files to the MSD will proceed as follows:
Given a query MIDI file, we first synthesize it using \prettymidi{}'s \texttt{fluidsynth} method.
Then, we compute the log-magnitude, $L^2$-normalized, constant-Q spectrogram representation utilized throughout this thesis.
Using the pre-trained models from \cref{ch:dtw,ch:pse}, we compute the MIDI file's downsampled hash sequence and embedding.
We then compute the pairwise distance between the resulting embedding and all pre-computed embeddings of entries in the MSD, rank the entries according to their distance, and discard all but the top $N_{PSE}$.
We perform a similar pruning with the downsampled hash sequences, computing the DTW distance between the query and top $N_{PSE}$ MSD entries, ranking by distance, and discarding all but the top $N_{DHS}$.
Finally, we align the MIDI file to the remaining $N_{DHS}$ entries utilizing the system of \cref{sec:goldstandard}.

Before proceeding, we must first decide the pruning thresholds $N_{PSE}$ and $N_{DHS}$.
Choosing these thresholds directly trades off precision and computation, because setting larger thresholds will decrease the likelihood of discarding a valid match but will result in more comparisons being made downstream.
Based on the results of \cref{sec:ranking,sec:pse_results}, we chose $N_{PSE} = 100,000$ and $N_{DHS} = 250$.
This corresponds to pruning 90\% of the MSD in the first step, then pruning 99.75\% of the remaining entries, so that in the end the expensive DTW comparison is only performed on 0.025\% of the MSD.
According to our test-set results, this results in a false-reject rate of approximately 3.5\% for the embedded distance pruning and xxx\% for the downsampled hash sequences.
Assuming false rejects occur in each step independently, we can expect a combined false reject rate of up to xxx\%.

\subsection{Shortcuts}

Overall, we will follow the matching processes of \cref{sec:goldstandard,sec:hashing_system,sec:pse_specifics}, except for the following two changes made for efficiency:

First, we utilize an exact pruning method in the downsampled hash sequence-based pruning step.
Assuming we are computing the DTW distance as defined in \cref{sec:dtw} between two sequences, one of length $M$ and one of length $N$ with $M \le N$, then the normalized DTW distance will never be smaller than $T$ if there are not at least $M$ pairwise distances less than $T$.
Given this, while computing the pairwise distance matrix for downsampled hash sequences, we can (with a minor performance penalty) keep track of the number of entries which are smaller than $T$, where $T$ is set to the smallest normalized DTW distance which has been encountered so far.
If fewer than $M$ entries are less than $T$, we can skip computing the DTW alignment path because we can guarantee that the resulting normalized DTW distance will not be smaller than $T$.
In practice, this avoids the expensive operation of computing the DTW distance for many candidates whose distance matrices dictate that they cannot be the correct match.

Second, instead of utilizing the median pairwise distance for the CQT-to-CQT DTW additive penalty as suggested in \cref{sec:goldstandard}, we will use the mean distance.
This choice is largely made for performance reasons; computing the median of the $MN$ distances is at least $\mathcal{O}( NM\log(NM) )$ complexity whereas computing the mean is always $\mathcal{O}(NM)$.
We justify this decision based on the discussion in \cref{sec:optimizing} which suggests that small changes to the additive penalty will not affect alignment quality.
In practice, we found the mean and median pairwise distance to be extremely close, so this change likely has a negligible effect on the results aside from a small speed-up.

\subsection{Measuring Performance}

Exact same approach as in DHS and PSE chapters
Used mean for additive penalty
Based on the pruning thresholds chosen, we expect a performance of xxx.
We don't expect top-match all the time.

\subsection{The MIDI Dataset}

How many matches?  Plot of proportion of min score per MIDI file.
Benchmarking speed - steps required (synthesize, spectrogram, DHS, PSE, match, match, match)  Total time taken.
Distribution format - original MIDI files, for when different audio is available and/or a better alignment scheme is available.

\section{Deriving Ground-Truth Information}
\label{sec:deriving}

Obvious: Train content-based MIR systems on derived ground-truth information.
We also have a very large of richly annotated MIDI files.
We can do things like look at transcription statistics for different genres; basically improve on the Serra paper.
We can also query by riff more accurately.
Use multiple MIDI transcriptions as different ground truth data views.
Learn to invert MIDI piano rolls.
Musical language model.

\subsection{Comparison to Hand-Annotated Data}
\label{sec:reliability}

In order to utilize many of these sources of information, we need to align, using the system of 3dtw.
How accurate is the result?
Test beats and key

\subsubsection{Key Experiment}

\subsubsection{Beat Experiment}

\subsubsection{Improving Alignment as a Proxy for Content-Based MIR}

Ground truth is already valuable; we can make it more reliable by making alignment better.

\section{Ideas and Improvements}
\label{sec:ideas}

Try improving DTW by using the same representation learning approach.
Try learning DTW end-to-end.
Better recurrent network learning for embedding.
Hierarchy of approaches.
Applying to other areas: Cover song ID.  Speaker ID.  Plagiarism detection.
