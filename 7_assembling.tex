\chapter{Assembling a Collection of MIDI Files Matched to the Million Song Dataset}
\label{ch:assembling}

We have all the ingredients.
Choosing thresholds - plot of time-to-reach pruning thresholds.
Total time taken.
Statistics of resulting MIDI files.
Extracting ground truth.
Distribution format - original MIDI files, for when different audio is available and/or a better alignment scheme is available.
JAMS structure.

\section{Ideas and Improvements}

Obvious: Train content-based MIR systems on derived ground-truth information.
We also have a very large of richly annotated MIDI files.
We can do things like look at transcription statistics for different genres; basically improve on the Serra paper.
We can also query by riff more accurately.
Use multiple MIDI transcriptions as different ground truth data views.
Learn to invert MIDI piano rolls.

Try improving DTW by using the same representation learning approach.
Try learning DTW end-to-end.
Better recurrent network learning for embedding.
Problems with content-based MIR tasks (evaluation).
